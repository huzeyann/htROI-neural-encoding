{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.config import get_cfg_defaults\n",
    "from src.data.datamodule import MyDataModule\n",
    "from src.models.ube import UBE\n",
    "from src.utils.callbacks import MyScoreFinetuning\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from src.train import tune_ube_grid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0220 10:07:25.460465390 2029941 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0220 10:07:25.485623112 2029941 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0220 10:07:25.493778457 2029941 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-02-20 10:07:26,746\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "E0220 10:07:26.748044424 2029941 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-20 10:07:26 (running for 00:00:00.21)\n",
      "Memory usage on this node: 6.1/62.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/20 CPUs, 1.0/2 GPUs, 0.0/35.0 GiB heap, 0.0/17.5 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/huze/ray_results/tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+----------------------------+----------+-----------------------+-------------------------+\n",
      "| Trial name                 | status   | loc                   | MODEL.BACKBONE.LAYERS   |\n",
      "|----------------------------+----------+-----------------------+-------------------------|\n",
      "| train_ube_tune_d0b2a_00000 | RUNNING  | 113.54.130.84:2034132 | x3                      |\n",
      "| train_ube_tune_d0b2a_00001 | PENDING  |                       | x4                      |\n",
      "+----------------------------+----------+-----------------------+-------------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 1\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m ['MODEL.BACKBONE.LAYERS', 'x3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decode and transform: 100%|██████████| 1102/1102 [00:00<00:00, 79717.89it/s]\n",
      "decode and transform:   0%|          | 0/1102 [00:00<?, ?it/s]\n",
      "decode and transform: 100%|██████████| 1102/1102 [00:00<00:00, 76174.61it/s]\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m Using 16bit native Automatic Mixed Precision (AMP)\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m GPU available: True, used: True\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m TPU available: False, using: 0 TPU cores\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m IPU available: False, using: 0 IPUs\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m   rank_zero_deprecation(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m   rank_zero_deprecation(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 1\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m ['MODEL.BACKBONE.LAYERS', 'x4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decode and transform: 100%|██████████| 1102/1102 [00:00<00:00, 80749.88it/s]\n",
      "decode and transform:   0%|          | 0/1102 [00:00<?, ?it/s]\n",
      "decode and transform: 100%|██████████| 1102/1102 [00:00<00:00, 76305.40it/s]\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m Using 16bit native Automatic Mixed Precision (AMP)\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m GPU available: True, used: True\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m TPU available: False, using: 0 TPU cores\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m IPU available: False, using: 0 IPUs\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m   rank_zero_deprecation(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m   rank_zero_deprecation(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m Weight decoupling enabled in AdaBelief\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m Rectification enabled in AdaBelief\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/loggers/csv_logs.py:57: UserWarning: Experiment logs directory /home/huze/ray_results/tune_mnist_asha/train_ube_tune_d0b2a_00000_0_MODEL.BACKBONE.LAYERS=x3_2022-02-20_10-07-26/. exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m   rank_zero_warn(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m \n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m   | Name     | Type     | Params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m --------------------------------------\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 0 | backbone | ResNet3D | 46.8 M\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 1 | neck     | I3DNeck  | 39.3 M\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m --------------------------------------\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 39.3 M    Trainable params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 46.7 M    Non-trainable params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 86.1 M    Total params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m 172.141   Total estimated model params size (MB)\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.316968597 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.349940831 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.384216281 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.421516229 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.460230446 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.499387118 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.568674922 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:32.600664538 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-20 10:07:32 (running for 00:00:06.16)\n",
      "Memory usage on this node: 15.8/62.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/20 CPUs, 2.0/2 GPUs, 0.0/35.0 GiB heap, 0.0/17.5 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/huze/ray_results/tune_mnist_asha\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+----------------------------+----------+-----------------------+-------------------------+\n",
      "| Trial name                 | status   | loc                   | MODEL.BACKBONE.LAYERS   |\n",
      "|----------------------------+----------+-----------------------+-------------------------|\n",
      "| train_ube_tune_d0b2a_00000 | RUNNING  | 113.54.130.84:2034132 | x3                      |\n",
      "| train_ube_tune_d0b2a_00001 | RUNNING  | 113.54.130.84:2034131 | x4                      |\n",
      "+----------------------------+----------+-----------------------+-------------------------+\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m   rank_zero_warn(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.137582774 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.168150132 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.197872623 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.228164766 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.258393155 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.288426570 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.318580907 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.348782950 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m Weight decoupling enabled in AdaBelief\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m Rectification enabled in AdaBelief\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:  50%|█████     | 1/2 [00:00<00:00,  1.18it/s, loss=0.292, v_num=._.]\n",
      "Validating: 0it [00:00, ?it/s]\u001B[A132)\u001B[0m \n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/loggers/csv_logs.py:57: UserWarning: Experiment logs directory /home/huze/ray_results/tune_mnist_asha/train_ube_tune_d0b2a_00001_1_MODEL.BACKBONE.LAYERS=x4_2022-02-20_10-07-27/. exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m   rank_zero_warn(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m \n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m   | Name     | Type     | Params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m --------------------------------------\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 0 | backbone | ResNet3D | 46.8 M\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 1 | neck     | I3DNeck  | 39.5 M\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m --------------------------------------\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 39.6 M    Trainable params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 46.7 M    Non-trainable params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 86.3 M    Total params\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m 172.665   Total estimated model params size (MB)\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:33.952905031 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:33.984774234 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.018000129 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.052911182 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:33.995199551 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.044135502 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.084548949 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.118948847 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.081028121 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.120642624 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.156291433 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.184659491 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:34.212457270 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.191551527 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.235273559 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:34.276740819 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]                        \n",
      "Result for train_ube_tune_d0b2a_00000:\n",
      "  date: 2022-02-20_10-07-35\n",
      "  done: false\n",
      "  experiment_id: e49d74b8979346f3ba436ab004b9c1c5\n",
      "  hostname: yfwu-guslab\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 113.54.130.84\n",
      "  pid: 2034132\n",
      "  time_since_restore: 7.2056872844696045\n",
      "  time_this_iter_s: 7.2056872844696045\n",
      "  time_total_s: 7.2056872844696045\n",
      "  timestamp: 1645369655\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0b2a_00000\n",
      "  val_corr: -0.010981758125126362\n",
      "  \n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m \n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it, loss=0.292, v_num=._., val_mse_loss/final=0.282, val_corr=-.011]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it, loss=0.292, v_num=._., val_mse_loss/final=0.282, val_corr=-.011, train_mse_loss/final=0.292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m /home/huze/env_ube/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m   rank_zero_warn(\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.077839799 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.107068547 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.135940086 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.165005580 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.194509338 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.227258188 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.256783269 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:35.288870383 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.292, v_num=._., val_mse_loss/final=0.282, val_corr=-.011, train_mse_loss/final=0.292]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.631415253 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.666606250 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.701339056 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.729577927 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.759536070 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.789394766 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.735409504 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.768736443 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.802292737 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it, loss=0.311, v_num=._.]\n",
      "Validating: 0it [00:00, ?it/s]\u001B[A131)\u001B[0m \n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.819561653 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.849431522 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.879337202 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.836146262 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:36.869612650 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.913503464 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m E0220 10:07:36.972778465 2034754 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:38.076844156 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:38.111838109 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-02-20 10:07:38,149\tWARNING tune.py:592 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 1/2 [00:01<00:01,  1.54s/it, loss=0.249, v_num=._., val_mse_loss/final=0.282, val_corr=-.011, train_mse_loss/final=0.292]\n",
      "Validating: 0it [00:00, ?it/s]\u001B[A132)\u001B[0m \n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "== Status ==\n",
      "Current time: 2022-02-20 10:07:38 (running for 00:00:11.38)\n",
      "Memory usage on this node: 24.4/62.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/20 CPUs, 2.0/2 GPUs, 0.0/35.0 GiB heap, 0.0/17.5 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: d0b2a_00000 with val_corr=-0.010981758125126362 and parameters={'MODEL.BACKBONE.LAYERS': 'x3'}\n",
      "Result logdir: /home/huze/ray_results/tune_mnist_asha\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+----------------------------+----------+-----------------------+-------------------------+------------+----------------------+\n",
      "| Trial name                 | status   | loc                   | MODEL.BACKBONE.LAYERS   |   val_corr |   training_iteration |\n",
      "|----------------------------+----------+-----------------------+-------------------------+------------+----------------------|\n",
      "| train_ube_tune_d0b2a_00000 | RUNNING  | 113.54.130.84:2034132 | x3                      | -0.0109818 |                    1 |\n",
      "| train_ube_tune_d0b2a_00001 | RUNNING  | 113.54.130.84:2034131 | x4                      |            |                      |\n",
      "+----------------------------+----------+-----------------------+-------------------------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-20 10:07:38 (running for 00:00:11.38)\n",
      "Memory usage on this node: 24.4/62.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/20 CPUs, 2.0/2 GPUs, 0.0/35.0 GiB heap, 0.0/17.5 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: d0b2a_00000 with val_corr=-0.010981758125126362 and parameters={'MODEL.BACKBONE.LAYERS': 'x3'}\n",
      "Result logdir: /home/huze/ray_results/tune_mnist_asha\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+----------------------------+----------+-----------------------+-------------------------+------------+----------------------+\n",
      "| Trial name                 | status   | loc                   | MODEL.BACKBONE.LAYERS   |   val_corr |   training_iteration |\n",
      "|----------------------------+----------+-----------------------+-------------------------+------------+----------------------|\n",
      "| train_ube_tune_d0b2a_00000 | RUNNING  | 113.54.130.84:2034132 | x3                      | -0.0109818 |                    1 |\n",
      "| train_ube_tune_d0b2a_00001 | RUNNING  | 113.54.130.84:2034131 | x4                      |            |                      |\n",
      "+----------------------------+----------+-----------------------+-------------------------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034131)\u001B[0m \n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:38.148345692 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:38.184272575 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001B[2m\u001B[36m(train_ube_tune pid=2034132)\u001B[0m E0220 10:07:38.220562653 2034742 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-02-20 10:07:38,355\tERROR tune.py:632 -- Trials did not complete: [train_ube_tune_d0b2a_00000, train_ube_tune_d0b2a_00001]\n",
      "2022-02-20 10:07:38,355\tINFO tune.py:636 -- Total run time: 11.61 seconds (11.38 seconds for the tuning loop).\n",
      "2022-02-20 10:07:38,356\tWARNING tune.py:640 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'MODEL.BACKBONE.LAYERS': 'x3'}\n"
     ]
    }
   ],
   "source": [
    "tune_ube_grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}