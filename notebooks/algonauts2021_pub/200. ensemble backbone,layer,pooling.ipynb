{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a0d34-3dee-4654-9267-3aa5ac4549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path('/data/huze/ray_results/algonauts2021')\n",
    "print('results_dir', results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b44289-8bd0-4e99-aa85-37214278f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.runs import load_run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b8160-26f1-4955-aa8d-1c7220ee46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = load_run_df(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8e846",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3280208-c03b-4d39-bb79-1ed310766f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ensemble import optimize_val_correlation\n",
    "from src.config.config import combine_cfgs, get_cfg_defaults\n",
    "from src.data.datamodule import MyDataModule\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24e67d90-7710-40f3-b4c4-63920e63e165",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prepare train and validation data\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.DATASET.TRANSFORM = 'i3d_flow'\n",
    "dm = MyDataModule(cfg)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "val_indices = dm.val_dataset.indices\n",
    "fmris_cache_path = Path('/data/huze/.cache/trainval_fmris.pt')\n",
    "\n",
    "if fmris_cache_path.exists():\n",
    "    fmris = torch.load(fmris_cache_path)\n",
    "else:\n",
    "    fmris = [dm.dataset_train_val.__getitem__(i)[1]\n",
    "             for i in tqdm(range(dm.dataset_train_val.__len__()))]\n",
    "    fmris = np.stack(fmris, 0)\n",
    "    fmris = torch.tensor(fmris)\n",
    "    torch.save(fmris, fmris_cache_path)\n",
    "\n",
    "val_fmris = fmris[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b233b8-7640-4c44-8b7e-ae5fea65844c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0383480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_prediction_from_tensor_list(predicions_list, roi_val_fmris, val_indices, opt_verbose=False, tol=1e-4):\n",
    "    predictions = torch.stack(predicions_list, -1)\n",
    "    ws = optimize_val_correlation(predictions[val_indices],\n",
    "                                  roi_val_fmris,\n",
    "                                  verbose=opt_verbose,\n",
    "                                  device=DEVICE,\n",
    "                                  tol=tol)\n",
    "    new_predictions = predictions @ ws\n",
    "    return new_predictions\n",
    "\n",
    "\n",
    "def get_ensemble_prediction_from_df(roi_df, val_indices, roi_val_fmris, roi_voxel_indices, opt_verbose=False, tol=1e-4):\n",
    "    predictions = np.stack([\n",
    "        np.load(path.joinpath('prediction.npy'))\n",
    "        for path in roi_df['path'].values\n",
    "    ], -1)\n",
    "\n",
    "    predictions = torch.tensor(predictions).float()\n",
    "    ws = optimize_val_correlation(predictions[val_indices],\n",
    "                                  roi_val_fmris,\n",
    "                                  verbose=opt_verbose,\n",
    "                                  device=DEVICE,\n",
    "                                  tol=tol)\n",
    "    new_predictions = predictions @ ws\n",
    "    return new_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68fb198",
   "metadata": {},
   "source": [
    "# 3 level of hierarchical ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "877058e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.rigistry import Registry\n",
    "from src.utils.misc import my_query_df\n",
    "\n",
    "ORDERED_HIERACHY_KEYS = ['MODEL.BACKBONE.NAME', 'MODEL.BACKBONE.LAYERS', 'MODEL.NECK.SPP_LEVELS']\n",
    "\n",
    "HEFN_REGISTRY = Registry()\n",
    "\n",
    "@HEFN_REGISTRY.register('H1')\n",
    "def H1_ens_roi(run_df, roi, verbose=True, opt_verbose=False, he_keys=ORDERED_HIERACHY_KEYS):\n",
    "    run_df = run_df.loc[run_df['DATASET.ROI'] == roi]\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "    if verbose:\n",
    "        print('Level 1...\\t', roi, '\\t')\n",
    "\n",
    "    new_predictions = get_ensemble_prediction_from_df(run_df, val_indices,\n",
    "                                                      roi_val_fmris, roi_voxel_indices, opt_verbose=opt_verbose)\n",
    "\n",
    "    return new_predictions\n",
    "\n",
    "\n",
    "@HEFN_REGISTRY.register('H2')\n",
    "def H2_ens_roi(run_df, roi, verbose=True, opt_verbose=False, he_keys=ORDERED_HIERACHY_KEYS):\n",
    "    run_df = run_df.loc[run_df['DATASET.ROI'] == roi]    \n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "    o_predictions_list = []\n",
    "    for v1 in run_df[he_keys[0]].unique():\n",
    "        _l1_df = my_query_df(run_df, equal_dict={he_keys[0]: v1})\n",
    "\n",
    "        if verbose:\n",
    "            print('Level 1...\\t', roi, v1, '\\t')\n",
    "        new_predictions = get_ensemble_prediction_from_df(_l1_df, val_indices,\n",
    "                                                          roi_val_fmris, roi_voxel_indices, opt_verbose=opt_verbose)\n",
    "        o_predictions_list.append(new_predictions)\n",
    "\n",
    "    if verbose:\n",
    "        print('Level 2...\\t', roi, '\\t')\n",
    "    new_predictions = get_ensemble_prediction_from_tensor_list(o_predictions_list, roi_val_fmris, val_indices,\n",
    "                                                               opt_verbose=opt_verbose)\n",
    "    return new_predictions\n",
    "\n",
    "\n",
    "@HEFN_REGISTRY.register('H3')\n",
    "def H3_ens_roi(run_df, roi, verbose=True, opt_verbose=False, he_keys=ORDERED_HIERACHY_KEYS):\n",
    "    run_df = run_df.loc[run_df['DATASET.ROI'] == roi]    \n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "    oo_predictions_list = []\n",
    "    for v2 in run_df[he_keys[0]].unique():\n",
    "        _l2_df = my_query_df(run_df, equal_dict={he_keys[0]: v2})\n",
    "        o_predictions_list = []\n",
    "        for v1 in _l2_df[he_keys[1]].unique():\n",
    "            _l1_df = my_query_df(_l2_df, equal_dict={he_keys[1]: v1})\n",
    "            if verbose:\n",
    "                print('Level 1...\\t', roi, v2, v1, '\\t')\n",
    "            new_predictions = get_ensemble_prediction_from_df(_l1_df, val_indices,\n",
    "                                                              roi_val_fmris, roi_voxel_indices, opt_verbose=opt_verbose)\n",
    "            o_predictions_list.append(new_predictions)\n",
    "\n",
    "        if verbose:\n",
    "            print('Level 2...\\t', roi, v2, '\\t')\n",
    "        new_predictions = get_ensemble_prediction_from_tensor_list(o_predictions_list, roi_val_fmris, val_indices,\n",
    "                                                                   opt_verbose=opt_verbose)\n",
    "        oo_predictions_list.append(new_predictions)\n",
    "    if verbose:\n",
    "        print('Level 3...\\t', roi, '\\t')\n",
    "    new_predictions = get_ensemble_prediction_from_tensor_list(oo_predictions_list, roi_val_fmris, val_indices,\n",
    "                                                               opt_verbose=opt_verbose)\n",
    "    return new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c51d4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_rois_to_full_brain(roi_sch_dict, roi_prediction_dict, shape):\n",
    "    # combine rois to full brain\n",
    "    sch_prediction_dict = {}\n",
    "    for sch_name, sch_rois in roi_sch_dict.items():\n",
    "        prediction = torch.zeros(shape)\n",
    "        for roi in sch_rois:\n",
    "            voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "            prediction[..., voxel_indices] = roi_prediction_dict[roi]\n",
    "        sch_prediction_dict[sch_name] = prediction\n",
    "    return sch_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2c2b0-d75b-452a-8c3d-e0b22d11d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d0a4e2b-4c9b-4b60-993e-10dd336e9163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESCRIPTION', 'DATAMODULE.NUM_CV_SPLITS', 'DATAMODULE.I_CV_FOLD',\n",
       "       'DATASET.NAME', 'DATASET.ROOT_DIR', 'DATASET.TRANSFORM',\n",
       "       'DATASET.RESOLUTION', 'DATASET.FRAMES', 'DATASET.VOXEL_INDEX_DIR',\n",
       "       'DATASET.ROI', 'MODEL.BACKBONE.NAME', 'MODEL.BACKBONE.PRETRAINED',\n",
       "       'MODEL.BACKBONE.PRETRAINED_WEIGHT_DIR', 'MODEL.BACKBONE.DISABLE_BN',\n",
       "       'MODEL.BACKBONE.LAYERS', 'MODEL.BACKBONE.LAYER_PATHWAYS',\n",
       "       'MODEL.NECK.NECK_TYPE', 'MODEL.NECK.FIRST_CONV_SIZE',\n",
       "       'MODEL.NECK.POOLING_MODE', 'MODEL.NECK.SPP_LEVELS',\n",
       "       'MODEL.NECK.FC_ACTIVATION', 'MODEL.NECK.FC_HIDDEN_DIM',\n",
       "       'MODEL.NECK.FC_NUM_LAYERS', 'MODEL.NECK.FC_BATCH_NORM',\n",
       "       'MODEL.NECK.FC_DROPOUT', 'MODEL.NECK.LSTM.HIDDEN_SIZE',\n",
       "       'MODEL.NECK.LSTM.NUM_LAYERS', 'MODEL.NECK.LSTM.BIDIRECTIONAL',\n",
       "       'OPTIMIZER.NAME', 'OPTIMIZER.LR', 'OPTIMIZER.WEIGHT_DECAY',\n",
       "       'SCHEDULER.NAME', 'TRAINER.GPUS', 'TRAINER.FP16', 'TRAINER.MAX_EPOCHS',\n",
       "       'TRAINER.ACCUMULATE_GRAD_BATCHES', 'TRAINER.BATCH_SIZE',\n",
       "       'TRAINER.VAL_CHECK_INTERVAL',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.INITIAL_RATIO_LR',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.LR_MULTIPLY_EFFICIENT',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.DEFROST_SCORE',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.SHOULD_ALIGN',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.TRAIN_BN',\n",
       "       'TRAINER.CALLBACKS.BACKBONE.VERBOSE',\n",
       "       'TRAINER.CALLBACKS.EARLY_STOP.PATIENCE',\n",
       "       'TRAINER.CALLBACKS.CHECKPOINT.ROOT_DIR',\n",
       "       'TRAINER.CALLBACKS.CHECKPOINT.RM_AT_DONE', 'RESULTS_DIR', 'DEBUG',\n",
       "       'path', 'score', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "107eaeca-d416-43b0-b1d2-2a94f3c47712",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = run_df[run_df['TRAINER.CALLBACKS.BACKBONE.DEFROST_SCORE'] < 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2ab5e",
   "metadata": {},
   "source": [
    "# define ensemble sche gird space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37d80937-faec-4a71-b356-065449a27460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ced0604-8c9e-4833-9950-cffdea3907b5",
   "metadata": {},
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"\n",
    "    powerset([1,2,3]) --> (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "    \"\"\"\n",
    "    xs = list(iterable)\n",
    "    # note we return an iterator rather than a list\n",
    "    return chain.from_iterable(combinations(xs, n) for n in range(1, len(xs) + 1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7321621-35cd-4534-b650-4918cf29a1c3",
   "metadata": {},
   "source": [
    "# MODEL.BACKBONE.LAYERS\n",
    "_model_sch_dfs = {\n",
    "    \"single_layer+multi_layer\": run_df,\n",
    "    \"single_layer\": run_df[run_df.apply(lambda row: len(row['MODEL.BACKBONE.LAYERS']) == 1, axis=1)],\n",
    "    \"multi_layer\": run_df[run_df.apply(lambda row: len(row['MODEL.BACKBONE.LAYERS']) > 1, axis=1)],\n",
    "}\n",
    "\n",
    "# MODEL.BACKBONE.NAME\n",
    "model_sch_dfs = {}\n",
    "\n",
    "backbones = run_df['MODEL.BACKBONE.NAME'].unique()\n",
    "for key, df in _model_sch_dfs.items():\n",
    "    for backbone_subset in powerset(backbones):\n",
    "        i_df = pd.concat([df.loc[df['MODEL.BACKBONE.NAME'] == backbone] for backbone in backbone_subset])\n",
    "        backbone_subset_name = '+'.join(backbone_subset)\n",
    "\n",
    "        model_sch_dfs[f'{key}&{backbone_subset_name}'] = i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b18e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dict defines how to combine rois to full brain\n",
    "roi_sch_dict = {\n",
    "    'WB': ['WB'],\n",
    "    'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
    "    'S-htROI': [f'S-htROI{i+1}' for i in range(8)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1b38e",
   "metadata": {},
   "source": [
    "# ensemble configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1d3b382-f7ca-424c-bdc6-ad52733c5cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/huze/ray_results/algonauts2021')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3956e63-bf06-4ff5-8a57-a76b7b8eb255",
   "metadata": {},
   "source": [
    "rm -r /data/huze/ray_results/algonauts2021/notebook200/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efde7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = results_dir.joinpath('notebook200')\n",
    "save_dir.mkdir(parents=False, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc6e97c7-52ba-41ad-abbb-c4ea11d8d4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/huze/ray_results/algonauts2021/notebook200')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19c06d98-2895-4bd9-aa19-ae4c42dd0888",
   "metadata": {},
   "source": [
    "ll /data/huze/ray_results/algonauts2021/notebook200"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a8e286d-e047-41f6-8425-94509f7cc8a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def iprint(list):\n",
    "    for (num, item) in enumerate(list):\n",
    "        print(num, item)\n",
    "    print()\n",
    "\n",
    "\n",
    "model_schs = np.asarray(list(model_sch_dfs.keys()))\n",
    "print(\"model_schs\")\n",
    "iprint(model_schs)\n",
    "he_schs = np.asarray(list(HEFN_REGISTRY.keys()))\n",
    "print(\"he_schs\")\n",
    "iprint(he_schs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "688e15ed-2e19-4ae5-b404-278c905189ed",
   "metadata": {},
   "source": [
    "ensemble_configs = []\n",
    "ensemble_configs += list(itertools.product(model_schs[np.asarray([5])], he_schs)) # compare `hierachical` sch\n",
    "ensemble_configs += list(itertools.product(model_schs, he_schs[np.asarray([2])])) # fix `hierachical` sch\n",
    "ensemble_configs = set(ensemble_configs) # remove duplicate\n",
    "pprint(ensemble_configs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a507397-fc0a-4567-9270-164e40b1e271",
   "metadata": {},
   "source": [
    "ensemble_configs = {('H3', roi_sch) for roi_sch in roi_sch_dict.keys()}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "724194be-f572-47f5-ab7e-92ff90e7f28a",
   "metadata": {},
   "source": [
    "ensemble_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db145c40-65a7-4ddc-9f36-d01ae63c6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = sum(list(roi_sch_dict.values()), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98401932-9f75-4faf-90d7-1c79ce7ba427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WB',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'EBA',\n",
       " 'LOC',\n",
       " 'PPA',\n",
       " 'FFA',\n",
       " 'STS',\n",
       " 'REST',\n",
       " 'S-htROI1',\n",
       " 'S-htROI2',\n",
       " 'S-htROI3',\n",
       " 'S-htROI4',\n",
       " 'S-htROI5',\n",
       " 'S-htROI6',\n",
       " 'S-htROI7',\n",
       " 'S-htROI8']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283d17d-84ff-474e-9558-b0ca1ede8268",
   "metadata": {},
   "source": [
    "# heavy lift for each roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0902141c-7ad3-4ab9-b557-9976d62ec5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_save_dir = save_dir.joinpath(Path('roi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74b600f3-b38d-4b1f-9731-876d9ef5e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/huze/ray_results/algonauts2021/notebook200/roi')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_save_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84c41298-7a10-47d1-bb7a-2398372f179d",
   "metadata": {},
   "source": [
    "rm -r /data/huze/ray_results/algonauts2021/notebookdebug200/roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6a459ce-0fe9-49ba-ac15-2dbf3abb2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_save_dir.mkdir(parents=False, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51339026-fbe5-408f-8e64-81390fa0477e",
   "metadata": {},
   "source": [
    "# for main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d752b796-d07d-44ba-8f47-3943fc5f3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_sch = 'H3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f98a691e-002f-491a-8285-086b7d09f8e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac24245b774ff987f5595fb1e7f3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0d9a2500854d0ca580373b1efb4cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248603f0bc4941f2bbcb923fb60eb4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d0b98a1c794c9486e6330efc938dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6330284809bf46a9836bc3aa664b35d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5823cf735e74a9db271b38722c1d94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9e4db39b9a492699b96fb84b6b2a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1749f2352e27407fa23a741338a439e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563132b478054365a2b88c2b1c1ef105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f289d3a31c424465bae36db06bfc36d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94da7bfcc924563b04b09b33492ca5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H3 V1\n",
      "skipped existing ... H3 V2\n",
      "skipped existing ... H3 V3\n",
      "skipped existing ... H3 V4\n",
      "skipped existing ... H3 EBA\n",
      "skipped existing ... H3 LOC\n",
      "skipped existing ... H3 PPA\n",
      "skipped existing ... H3 FFA\n",
      "skipped existing ... H3 STS\n",
      "skipped existing ... H3 REST\n",
      "skipped existing ... H3 S-htROI1\n",
      "skipped existing ... H3 S-htROI2\n",
      "skipped existing ... H3 S-htROI3\n",
      "skipped existing ... H3 S-htROI4\n",
      "skipped existing ... H3 S-htROI5\n",
      "skipped existing ... H3 S-htROI6\n",
      "skipped existing ... H3 S-htROI7\n",
      "skipped existing ... H3 S-htROI8\n"
     ]
    }
   ],
   "source": [
    "# X model\n",
    "for b in run_df['MODEL.BACKBONE.NAME'].unique():\n",
    "    b_run_df = run_df[run_df['MODEL.BACKBONE.NAME'] == b]\n",
    "    \n",
    "    # Disk I/O is the bottle neck\n",
    "\n",
    "    verbose = True\n",
    "    opt_verbose = False\n",
    "    skip_existing = True\n",
    "\n",
    "    for roi in tqdm(rois[:]):\n",
    "        # skip existing files\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        if path.exists():\n",
    "            if skip_existing:\n",
    "                print('skipped existing ...', he_sch, roi)\n",
    "                continue\n",
    "\n",
    "        roi_prediction = HEFN_REGISTRY[he_sch](b_run_df, roi, verbose=verbose, opt_verbose=opt_verbose)\n",
    "\n",
    "        torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9a5b5a7-1734-4cc8-ad76-a2adbabd95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aa61c0d5644665835f53639db746ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 WB\n",
      "skipped existing ... H2 WB\n",
      "skipped existing ... H3 V1\n",
      "Level 1...\t V1 3d_swin \t\n",
      "Level 2...\t V1 \t\n",
      "skipped existing ... H3 V2\n",
      "Level 1...\t V2 3d_swin \t\n",
      "Level 2...\t V2 \t\n",
      "skipped existing ... H3 V3\n",
      "Level 1...\t V3 3d_swin \t\n",
      "Level 2...\t V3 \t\n",
      "skipped existing ... H3 V4\n",
      "Level 1...\t V4 3d_swin \t\n",
      "Level 2...\t V4 \t\n",
      "skipped existing ... H3 EBA\n",
      "Level 1...\t EBA 3d_swin \t\n",
      "Level 2...\t EBA \t\n",
      "skipped existing ... H3 LOC\n",
      "Level 1...\t LOC 3d_swin \t\n",
      "Level 2...\t LOC \t\n",
      "skipped existing ... H3 PPA\n",
      "Level 1...\t PPA 3d_swin \t\n",
      "Level 2...\t PPA \t\n",
      "skipped existing ... H3 FFA\n",
      "Level 1...\t FFA 3d_swin \t\n",
      "Level 2...\t FFA \t\n",
      "skipped existing ... H3 STS\n",
      "Level 1...\t STS 3d_swin \t\n",
      "Level 2...\t STS \t\n",
      "skipped existing ... H3 REST\n",
      "Level 1...\t REST 3d_swin \t\n",
      "Level 2...\t REST \t\n",
      "skipped existing ... H3 S-htROI1\n",
      "Level 1...\t S-htROI1 3d_swin \t\n",
      "Level 2...\t S-htROI1 \t\n",
      "skipped existing ... H3 S-htROI2\n",
      "Level 1...\t S-htROI2 3d_swin \t\n",
      "Level 2...\t S-htROI2 \t\n",
      "skipped existing ... H3 S-htROI3\n",
      "Level 1...\t S-htROI3 3d_swin \t\n",
      "Level 2...\t S-htROI3 \t\n",
      "skipped existing ... H3 S-htROI4\n",
      "Level 1...\t S-htROI4 3d_swin \t\n",
      "Level 2...\t S-htROI4 \t\n",
      "skipped existing ... H3 S-htROI5\n",
      "Level 1...\t S-htROI5 3d_swin \t\n",
      "Level 2...\t S-htROI5 \t\n",
      "skipped existing ... H3 S-htROI6\n",
      "Level 1...\t S-htROI6 3d_swin \t\n",
      "Level 2...\t S-htROI7 \t\n",
      "skipped existing ... H3 S-htROI8\n",
      "Level 1...\t S-htROI8 3d_swin \t\n",
      "Level 2...\t S-htROI8 \t\n"
     ]
    }
   ],
   "source": [
    "# for supplementary\n",
    "for roi in tqdm(rois[:]):\n",
    "    b = '3d_swin'\n",
    "    b_run_df = run_df[run_df['MODEL.BACKBONE.NAME'] == b]\n",
    "    verbose = True\n",
    "    opt_verbose = False\n",
    "    skip_existing = True\n",
    "\n",
    "    for he_sch in ['H3', 'H2']:\n",
    "        # skip existing files\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        if path.exists():\n",
    "            if skip_existing:\n",
    "                print('skipped existing ...', he_sch, roi)\n",
    "                continue\n",
    "\n",
    "        roi_prediction = HEFN_REGISTRY[he_sch](b_run_df, roi, verbose=verbose, opt_verbose=opt_verbose)\n",
    "\n",
    "        torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ede278-c79d-44ff-83a0-9bb3352ee18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2984fd4649f4426b87747afb1a833707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all models\n",
    "for roi in tqdm(rois[:]):\n",
    "    prediction_list = []\n",
    "    for b in run_df['MODEL.BACKBONE.NAME'].unique():\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        prediction = torch.load(path)\n",
    "        prediction_list.append(prediction)\n",
    "    \n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "    roi_prediction = get_ensemble_prediction_from_tensor_list(prediction_list, roi_val_fmris, val_indices)\n",
    "    \n",
    "    b = 'all'\n",
    "    path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "    torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7d1c8c-066c-4ca4-81bb-ae13b564c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46006834e75744689951b98c18203361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ed84dfc911443e81284dee426aa015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf1ed87db55431a85dcfa397a70c425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c92a961ca2d4ef986aabd3487102dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6168d9f4c2a64755a94f2367fee9fd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea17c9a16b04e8f80f870d03e453a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f3b702827947089e327b3256f58889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e7c5f36f5d4fc6b461e5d1756a2290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c913c2b5a846d69964a231e2dd63d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459acb8e26034c30b40319c40243e7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bfb7fc78574798b55e2d86e44c36db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all - X models\n",
    "for o_b in run_df['MODEL.BACKBONE.NAME'].unique():\n",
    "    for roi in tqdm(rois[:]):\n",
    "        prediction_list = []\n",
    "        for b in run_df['MODEL.BACKBONE.NAME'].unique():\n",
    "            if b == o_b: continue\n",
    "            path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "            prediction = torch.load(path)\n",
    "            prediction_list.append(prediction)\n",
    "\n",
    "        roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "        roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "        roi_prediction = get_ensemble_prediction_from_tensor_list(prediction_list, roi_val_fmris, val_indices)\n",
    "\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone=minus_{o_b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20ff44dd-2996-466c-9efb-89e37d37b6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f9056d989d42c093a2149709e0ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 - 11 models\n",
    "sorted_names = ['3d_swin', 'i3d_rgb', '2d_densnet_warp_3d',\n",
    "       '2d_simclr_warp_3d', '2d_moby_swin_warp_3d',\n",
    "       '2d_pyconvsegnet_warp_3d', '2d_seg_swin_warp_3d', 'i3d_flow',\n",
    "       '2d_colorizer_warp_3d', '2d_bdcnvgg_warp_3d', 'audio_vggish']\n",
    "\n",
    "for roi in tqdm(rois[:]):\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "    \n",
    "    prediction_list = []\n",
    "    for b in sorted_names:\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        prediction = torch.load(path)\n",
    "        prediction_list.append(prediction)\n",
    "\n",
    "        roi_prediction = get_ensemble_prediction_from_tensor_list(prediction_list, roi_val_fmris, val_indices)\n",
    "    \n",
    "        l = len(prediction_list)\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={l},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7da9df1-0aa6-405b-86b4-deb519fd1679",
   "metadata": {},
   "source": [
    "# 3 models\n",
    "sorted_names = ['3d_swin', 'i3d_rgb','i3d_flow']\n",
    "\n",
    "for roi in tqdm(rois[:]):\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "    \n",
    "    prediction_list = []\n",
    "    for b in sorted_names:\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        prediction = torch.load(path)\n",
    "        prediction_list.append(prediction)\n",
    "\n",
    "    roi_prediction = get_ensemble_prediction_from_tensor_list(prediction_list, roi_val_fmris, val_indices)\n",
    "\n",
    "    path = roi_save_dir.joinpath(Path(f'backbone=swin+rgb+flow,he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "    torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e86eb93-582e-4527-b27a-3d035614fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import vectorized_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b5543-bdc9-410e-9047-f8e39d58a031",
   "metadata": {},
   "source": [
    "for roi in ['WB']:\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "    \n",
    "    for l in range(1, 12):\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={l},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        prediction = torch.load(path)\n",
    "        \n",
    "        score = vectorized_correlation(prediction[val_indices], roi_val_fmris)\n",
    "        score /= noise_ceiling\n",
    "        score = score.mean().item()\n",
    "        print(l, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cdadf-d0b7-4d0a-90f8-2661f2c7acba",
   "metadata": {},
   "source": [
    "# 1 - 11 models (greedy)\n",
    "sorted_names = ['3d_swin', 'i3d_rgb', '2d_densnet_warp_3d',\n",
    "       '2d_simclr_warp_3d', '2d_moby_swin_warp_3d',\n",
    "       '2d_pyconvsegnet_warp_3d', '2d_seg_swin_warp_3d', 'i3d_flow',\n",
    "       '2d_colorizer_warp_3d', '2d_bdcnvgg_warp_3d', 'audio_vggish']\n",
    "\n",
    "for roi in ['WB']:\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "    \n",
    "    best_score = 0.\n",
    "    \n",
    "    prediction_list = []\n",
    "    for b in sorted_names:\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        prediction = torch.load(path)\n",
    "        tmp_prediction_list = prediction_list + [prediction]\n",
    "\n",
    "        roi_prediction = get_ensemble_prediction_from_tensor_list(tmp_prediction_list, roi_val_fmris, val_indices)\n",
    "        \n",
    "        score = vectorized_correlation(roi_prediction[val_indices], roi_val_fmris)\n",
    "        score /= noise_ceiling\n",
    "        score = score.mean().item()\n",
    "        print(b, score)\n",
    "        if score > best_score:\n",
    "            beest_score = score\n",
    "            prediction_list = tmp_prediction_list\n",
    "        \n",
    "        # l = len(prediction_list)\n",
    "        # path = roi_save_dir.joinpath(Path(f'backbone={l},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        # torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169604f-5606-4aa5-8b96-9c185063c78f",
   "metadata": {},
   "source": [
    "# \"assemble\" ROIs to full brain and save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b52fba85-bee2-4952-8962-61fd9535dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones = run_df['MODEL.BACKBONE.NAME'].unique().tolist() + ['all'] + [f'minus_{o_b}' for o_b in run_df['MODEL.BACKBONE.NAME'].unique()] + list(range(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25b7f244-5e32-4ed5-a060-ca85e48b7175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2d_pyconvsegnet_warp_3d',\n",
       " 'i3d_flow',\n",
       " '2d_seg_swin_warp_3d',\n",
       " 'i3d_rgb',\n",
       " '2d_moby_swin_warp_3d',\n",
       " '2d_colorizer_warp_3d',\n",
       " 'audio_vggish',\n",
       " '2d_densnet_warp_3d',\n",
       " '3d_swin',\n",
       " '2d_bdcnvgg_warp_3d',\n",
       " '2d_simclr_warp_3d',\n",
       " 'all',\n",
       " 'minus_2d_pyconvsegnet_warp_3d',\n",
       " 'minus_i3d_flow',\n",
       " 'minus_2d_seg_swin_warp_3d',\n",
       " 'minus_i3d_rgb',\n",
       " 'minus_2d_moby_swin_warp_3d',\n",
       " 'minus_2d_colorizer_warp_3d',\n",
       " 'minus_audio_vggish',\n",
       " 'minus_2d_densnet_warp_3d',\n",
       " 'minus_3d_swin',\n",
       " 'minus_2d_bdcnvgg_warp_3d',\n",
       " 'minus_2d_simclr_warp_3d',\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fde84581-bdfd-457e-862f-584b94281074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WB': ['WB'],\n",
       " 'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
       " 'S-htROI': ['S-htROI1',\n",
       "  'S-htROI2',\n",
       "  'S-htROI3',\n",
       "  'S-htROI4',\n",
       "  'S-htROI5',\n",
       "  'S-htROI6',\n",
       "  'S-htROI7',\n",
       "  'S-htROI8']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_sch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10dada92-a919-41a5-8eae-31a0eaed871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.submission import algonauts2021_submission_from_whole_brain_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33ae8b35-989a-4e0a-8b6d-25ddfcebf9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9579f971ad42e69aec8028c179afc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wb_shape = np.load(run_df.loc[run_df['DATASET.ROI'] == 'WB'].path.values[0].joinpath('prediction.npy')).shape\n",
    "\n",
    "for b in tqdm(backbones):\n",
    "\n",
    "    for roi_sch, rois in roi_sch_dict.items():\n",
    "\n",
    "        prediction = torch.zeros(wb_shape)\n",
    "\n",
    "        for roi in rois:\n",
    "            voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "            path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "            prediction[..., voxel_indices] = torch.load(path)\n",
    "\n",
    "        path = Path(os.path.join(save_dir, f'backbone={b},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "        torch.save(prediction, path)\n",
    "\n",
    "        # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "        #                                                 path.name.replace('-prediction.pt', ''),\n",
    "        #                                                 prediction[1000:].numpy(),\n",
    "        #                                                 output_dir='./submissions/full/',\n",
    "        #                                                 mini_track=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5aaed885-4c59-4e95-8b6a-6f3fdb24bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for supplementary\n",
    "wb_shape = np.load(run_df.loc[run_df['DATASET.ROI'] == 'WB'].path.values[0].joinpath('prediction.npy')).shape\n",
    "\n",
    "b = '3d_swin'\n",
    "\n",
    "for he_sch in ['H3', 'H2']:\n",
    "\n",
    "    for roi_sch, rois in roi_sch_dict.items():\n",
    "\n",
    "        prediction = torch.zeros(wb_shape)\n",
    "\n",
    "        for roi in rois:\n",
    "            voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "            path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "            prediction[..., voxel_indices] = torch.load(path)\n",
    "\n",
    "        path = Path(os.path.join(save_dir, f'backbone={b},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "        torch.save(prediction, path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b70cf9c-ed16-460e-beed-344056c4b485",
   "metadata": {},
   "source": [
    "wb_shape = np.load(run_df.loc[run_df['DATASET.ROI'] == 'WB'].path.values[0].joinpath('prediction.npy')).shape\n",
    "\n",
    "for b in ['swin+rgb+flow']:\n",
    "\n",
    "    for roi_sch, rois in roi_sch_dict.items():\n",
    "\n",
    "        prediction = torch.zeros(wb_shape)\n",
    "\n",
    "        for roi in rois:\n",
    "            voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "            path = roi_save_dir.joinpath(Path(f'backbone={b},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "            prediction[..., voxel_indices] = torch.load(path)\n",
    "\n",
    "        path = Path(os.path.join(save_dir, f'backbone={b},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "        torch.save(prediction, path)\n",
    "\n",
    "        # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "        #                                                 path.name.replace('-prediction.pt', ''),\n",
    "        #                                                 prediction[1000:].numpy(),\n",
    "        #                                                 output_dir='./submissions/full/',\n",
    "        #                                                 mini_track=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e12c44-5bec-4167-a040-84837d3d893e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79352d88-99c3-42ad-8e75-d8f5c5c3c6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25844f8-2b2c-4f0e-9290-d214cebbad9e",
   "metadata": {},
   "source": [
    "# ROI intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc706949-2256-4805-975d-9da23bcad82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect1d_multi_arr(arr_list):\n",
    "    intersect = arr_list[0]\n",
    "    for arr in arr_list[1:]:\n",
    "        intersect = np.intersect1d(intersect, arr)\n",
    "    return intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b21dad3d-e92c-4c83-9e56-80a8d8772c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.rigistry import Registry\n",
    "from src.utils.misc import my_query_df\n",
    "from src.utils.metrics import vectorized_correlation\n",
    "\n",
    "INTFN_REGISTRY = Registry()\n",
    "\n",
    "@INTFN_REGISTRY.register('grouped ensemble')\n",
    "def grouped_ensemble(prediction_list, val_indices, indiced_val_fmris, opt_verbose=False):\n",
    "    predictions = torch.stack(prediction_list, -1)\n",
    "    ws = optimize_val_correlation(predictions[val_indices],\n",
    "                                  indiced_val_fmris,\n",
    "                                  verbose=opt_verbose,\n",
    "                                  device=DEVICE)\n",
    "    new_predictions = predictions @ ws\n",
    "    return new_predictions\n",
    "\n",
    "\n",
    "@INTFN_REGISTRY.register('grouped swap')\n",
    "def grouped_swap(prediction_list, val_indices, indiced_val_fmris):\n",
    "    voxel_scores = np.asarray([\n",
    "        vectorized_correlation(p[val_indices], indiced_val_fmris).numpy()\n",
    "        for p in prediction_list\n",
    "    ])\n",
    "    croi_scores = voxel_scores.mean(1)\n",
    "\n",
    "    new_predictions = prediction_list[croi_scores.argmax()]\n",
    "    return new_predictions\n",
    "\n",
    "@INTFN_REGISTRY.register('voxel-wise swap')\n",
    "def voxel_wise_swap(prediction_list, val_indices, indiced_val_fmris):\n",
    "    voxel_scores = np.asarray([\n",
    "        vectorized_correlation(p[val_indices], indiced_val_fmris).numpy()\n",
    "        for p in prediction_list\n",
    "    ])\n",
    "        \n",
    "    vsargmax = voxel_scores.argmax(0)\n",
    "    new_predictions = torch.stack([prediction_list[idx][:, i] for i, idx in enumerate(vsargmax)], -1)\n",
    "    return new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29b9b09e-a1f4-4045-99bc-5f09ed4c7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_combinations(any_list):\n",
    "    return itertools.chain.from_iterable(\n",
    "        itertools.combinations(any_list, i + 1)\n",
    "        for i in range(len(any_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62decc20-3ce6-412e-9baa-64053ee82b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_roi_sch_dict_keys = list(all_combinations(roi_sch_dict.keys()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8199fde5-f0a1-4330-b492-719270dedcab",
   "metadata": {},
   "source": [
    "subset_roi_sch_dict_keys = list(itertools.combinations(list(roi_sch_dict.keys()), len(roi_sch_dict.keys())-1)) + [list(roi_sch_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0eba615-63f0-4089-bfa4-919de0072e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WB',),\n",
       " ('aROI',),\n",
       " ('S-htROI',),\n",
       " ('WB', 'aROI'),\n",
       " ('WB', 'S-htROI'),\n",
       " ('aROI', 'S-htROI'),\n",
       " ('WB', 'aROI', 'S-htROI')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_roi_sch_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3029c4e3-ca92-4f5b-a568-9a66e2eb90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_roi_sch_dicts = []\n",
    "for keys in subset_roi_sch_dict_keys:\n",
    "    d = {k: roi_sch_dict[k] for k in keys}\n",
    "    subset_roi_sch_dicts.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2ba2144-bee1-4bac-a645-017962c2ca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'WB': ['WB']},\n",
       " {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']},\n",
       " {'S-htROI': ['S-htROI1',\n",
       "   'S-htROI2',\n",
       "   'S-htROI3',\n",
       "   'S-htROI4',\n",
       "   'S-htROI5',\n",
       "   'S-htROI6',\n",
       "   'S-htROI7',\n",
       "   'S-htROI8']},\n",
       " {'WB': ['WB'],\n",
       "  'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']},\n",
       " {'WB': ['WB'],\n",
       "  'S-htROI': ['S-htROI1',\n",
       "   'S-htROI2',\n",
       "   'S-htROI3',\n",
       "   'S-htROI4',\n",
       "   'S-htROI5',\n",
       "   'S-htROI6',\n",
       "   'S-htROI7',\n",
       "   'S-htROI8']},\n",
       " {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
       "  'S-htROI': ['S-htROI1',\n",
       "   'S-htROI2',\n",
       "   'S-htROI3',\n",
       "   'S-htROI4',\n",
       "   'S-htROI5',\n",
       "   'S-htROI6',\n",
       "   'S-htROI7',\n",
       "   'S-htROI8']},\n",
       " {'WB': ['WB'],\n",
       "  'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
       "  'S-htROI': ['S-htROI1',\n",
       "   'S-htROI2',\n",
       "   'S-htROI3',\n",
       "   'S-htROI4',\n",
       "   'S-htROI5',\n",
       "   'S-htROI6',\n",
       "   'S-htROI7',\n",
       "   'S-htROI8']}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_roi_sch_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e95c515e-fc1b-43e2-b4ed-b10b606c3b86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3375e7f211d4439c9969e695d5ac50c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=i3d_rgb:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/huze/ray_results/algonauts2021/notebook200/backbone=i3d_rgb,he_sch=H3,roi_sch=i3d_rgb-htROI-prediction.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m wb_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m new_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m prediction_list \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir,\n\u001b[1;32m     16\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackbone=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,he_sch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhe_sch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,roi_sch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_sch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-prediction.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m roi_sch \u001b[38;5;129;01min\u001b[39;00m subset_roi_sch_dict\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prediction_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rois \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39msubset_roi_sch_dict\u001b[38;5;241m.\u001b[39mvalues())):\n",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m wb_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m new_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m prediction_list \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackbone=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbackbone\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,he_sch=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhe_sch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,roi_sch=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroi_sch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-prediction.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m roi_sch \u001b[38;5;129;01min\u001b[39;00m subset_roi_sch_dict\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prediction_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rois \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39msubset_roi_sch_dict\u001b[38;5;241m.\u001b[39mvalues())):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/env_ube/lib/python3.8/site-packages/torch/serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    592\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/env_ube/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/env_ube/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/huze/ray_results/algonauts2021/notebook200/backbone=i3d_rgb,he_sch=H3,roi_sch=i3d_rgb-htROI-prediction.pt'"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                   desc=f'backbone={backbone}'):\n",
    "        subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "        intersection_sch = 'grouped ensemble'\n",
    "\n",
    "        wb_shape = None\n",
    "        new_prediction = None\n",
    "        \n",
    "        prediction_list = [torch.load(os.path.join(save_dir,\n",
    "                         f'backbone={backbone},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "                   for roi_sch in subset_roi_sch_dict.keys()]\n",
    "        \n",
    "        if len(prediction_list) > 1:\n",
    "        \n",
    "            for rois in list(itertools.product(*subset_roi_sch_dict.values())):\n",
    "                voxel_indices_list = [torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt')) for roi in rois]\n",
    "                intersect = intersect1d_multi_arr(voxel_indices_list)\n",
    "\n",
    "                if wb_shape is None: wb_shape = prediction_list[0].shape\n",
    "                if new_prediction is None: new_prediction = torch.zeros(wb_shape)\n",
    "\n",
    "                intersect_prediction_list = [p[:, intersect] for p in prediction_list]\n",
    "\n",
    "                if len(intersect) > 0:\n",
    "                    new_prediction[:, intersect] = INTFN_REGISTRY[intersection_sch](intersect_prediction_list, val_indices, val_fmris[:, intersect])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            new_prediction = prediction_list[0]\n",
    "\n",
    "        torch.save(new_prediction, os.path.join(save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-prediction.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6f62ee66-0afb-43b0-b052-3b8b50b063c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/huze/ray_results/algonauts2021/notebook200')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31e0a7c8-41c1-4eb2-8531-5625f1960959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d408446b53d74b13934add9e38de86dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc07e38c2074cbe933f601320dec1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for supplementary\n",
    "for he_sch in ['H3', 'H2']:\n",
    "    for backbone in ['3d_swin']:\n",
    "        for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                       desc=f'backbone={backbone}'):\n",
    "            subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "            for intersection_sch in INTFN_REGISTRY.keys():\n",
    "\n",
    "                wb_shape = None\n",
    "                new_prediction = None\n",
    "\n",
    "                prediction_list = [torch.load(os.path.join(save_dir,\n",
    "                                 f'backbone={backbone},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "                           for roi_sch in subset_roi_sch_dict.keys()]\n",
    "\n",
    "                if len(prediction_list) > 1:\n",
    "\n",
    "                    for rois in list(itertools.product(*subset_roi_sch_dict.values())):\n",
    "                        voxel_indices_list = [torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt')) for roi in rois]\n",
    "                        intersect = intersect1d_multi_arr(voxel_indices_list)\n",
    "\n",
    "                        if wb_shape is None: wb_shape = prediction_list[0].shape\n",
    "                        if new_prediction is None: new_prediction = torch.zeros(wb_shape)\n",
    "\n",
    "                        intersect_prediction_list = [p[:, intersect] for p in prediction_list]\n",
    "\n",
    "                        if len(intersect) > 0:\n",
    "                            new_prediction[:, intersect] = INTFN_REGISTRY[intersection_sch](intersect_prediction_list, val_indices, val_fmris[:, intersect])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    new_prediction = prediction_list[0]\n",
    "\n",
    "                torch.save(new_prediction, os.path.join(save_dir,\n",
    "                                             f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                             f'-prediction.pt'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b558a75-0504-445e-b65c-5cd7c8a5c30f",
   "metadata": {},
   "source": [
    "for backbone in ['swin+rgb+flow']:\n",
    "    for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                   desc=f'backbone={backbone}'):\n",
    "        subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "        intersection_sch = 'grouped ensemble'\n",
    "\n",
    "        wb_shape = None\n",
    "        new_prediction = None\n",
    "        \n",
    "        prediction_list = [torch.load(os.path.join(save_dir,\n",
    "                         f'backbone={backbone},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "                   for roi_sch in subset_roi_sch_dict.keys()]\n",
    "        \n",
    "        if len(prediction_list) > 1:\n",
    "        \n",
    "            for rois in list(itertools.product(*subset_roi_sch_dict.values())):\n",
    "                voxel_indices_list = [torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt')) for roi in rois]\n",
    "                intersect = intersect1d_multi_arr(voxel_indices_list)\n",
    "\n",
    "                if wb_shape is None: wb_shape = prediction_list[0].shape\n",
    "                if new_prediction is None: new_prediction = torch.zeros(wb_shape)\n",
    "\n",
    "                intersect_prediction_list = [p[:, intersect] for p in prediction_list]\n",
    "\n",
    "                if len(intersect) > 0:\n",
    "                    new_prediction[:, intersect] = INTFN_REGISTRY[intersection_sch](intersect_prediction_list, val_indices, val_fmris[:, intersect])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            new_prediction = prediction_list[0]\n",
    "            \n",
    "        \n",
    "        path = Path(os.path.join(save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-prediction.pt'))\n",
    "\n",
    "        torch.save(new_prediction, path)\n",
    "        \n",
    "        algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "                                                        path.name.replace('-prediction.pt', ''),\n",
    "                                                        new_prediction[1000:].numpy(),\n",
    "                                                        output_dir='./submissions/',\n",
    "                                                        mini_track=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015972b-b7f5-47f9-95f0-bf9c211f225f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bcf3616-b793-48d9-9f51-705780d1cedc",
   "metadata": {},
   "source": [
    "# save WB+aROI+htROI weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6e74e0c-50ef-4565-bf70-b9bb8e0c2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_ensemble_weights(prediction_list, val_indices, indiced_val_fmris, opt_verbose=False):\n",
    "    predictions = torch.stack(prediction_list, -1)\n",
    "    ws = optimize_val_correlation(predictions[val_indices],\n",
    "                                  indiced_val_fmris,\n",
    "                                  verbose=opt_verbose,\n",
    "                                  device=DEVICE)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42df3da6-2d91-44cb-b9ce-d01072f1789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = [torch.load(os.path.join(save_dir,\n",
    "                 f'backbone=1,he_sch=H3,roi_sch={roi_sch}-prediction.pt'))\n",
    "           for roi_sch in ('WB', 'aROI', 'S-htROI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61b6ea94-0f29-45e6-be0a-a3c97675d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(val_fmris.shape[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa69aec4-a1e1-4200-b581-a52ddcca6883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63bb876e52e41fd8f9aec9a790b13db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for rois in tqdm(list(itertools.product(*subset_roi_sch_dicts[-1].values()))):\n",
    "    voxel_indices_list = [torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt')) for roi in rois]\n",
    "    intersect = intersect1d_multi_arr(voxel_indices_list)\n",
    "    \n",
    "    intersect_prediction_list = [p[:, intersect] for p in prediction_list]\n",
    "    \n",
    "    if len(intersect) > 0:\n",
    "        weights[intersect, :] = grouped_ensemble_weights(intersect_prediction_list, val_indices, val_fmris[:, intersect])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a9c953e-7c16-4cf8-8f5e-1e474d5263f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(weights, 'tmp/notebook200/WB+aROI+htROI weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81528b-dd4e-48c1-b0ad-bc7b459d4a03",
   "metadata": {},
   "source": [
    "# save to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a327f9c-23c0-44e2-853c-027ae0082fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import vectorized_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "601eb90c-c3a9-41a0-8858-53d866e03468",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_ceiling = np.load('config/noise_ceiling.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c87ccc50-212d-4c62-bce9-21e21d2d84f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/huze/ray_results/algonauts2021/notebook200')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73dde34f-fbe3-4ff8-a10f-413929628bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_save_dir = save_dir.joinpath(Path('score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6807bc5d-31d4-44f2-9820-5422ca4bbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_save_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f6bb21e-cb1b-4e68-b8fa-7a698c82d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae59a4feed7433da4a70a66cee175b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for backbone in tqdm(backbones):\n",
    "    for subset_roi_sch_dict in subset_roi_sch_dicts:\n",
    "        subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "        intersection_sch = 'grouped ensemble'\n",
    "        \n",
    "\n",
    "        prediction = torch.load(os.path.join(save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-prediction.pt'))\n",
    "        scores = vectorized_correlation(prediction[val_indices], val_fmris) / noise_ceiling\n",
    "        \n",
    "        \n",
    "        torch.save(scores, os.path.join(score_save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-score.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab10223e-b065-49b2-8603-a12904fcfc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59bd1f395c64e25b8a2580dce6753bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6bb645d98f42d485a01f73bf468820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for supplementary\n",
    "for he_sch in ['H3', 'H2']:\n",
    "    for backbone in ['3d_swin']:\n",
    "        for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                       desc=f'backbone={backbone}'):\n",
    "            subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "            for intersection_sch in INTFN_REGISTRY.keys():\n",
    "\n",
    "                prediction = torch.load(os.path.join(save_dir,\n",
    "                                             f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                             f'-prediction.pt'))\n",
    "                scores = vectorized_correlation(prediction[val_indices], val_fmris) / noise_ceiling\n",
    "\n",
    "\n",
    "                torch.save(scores, os.path.join(score_save_dir,\n",
    "                                             f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                             f'-score.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33f210ef-4871-4abd-a251-7601e5c950dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WB', 'aROI', 'S-htROI', 'WB+aROI', 'WB+S-htROI', 'aROI+S-htROI', 'WB+aROI+S-htROI']\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for subset_roi_sch_dict in subset_roi_sch_dicts:\n",
    "    subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "    ls.append(subset_roi_sch_text)\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb488283-2fb1-4717-b48f-8962bc3daef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['grouped ensemble', 'grouped swap', 'voxel-wise swap'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INTFN_REGISTRY.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9c456-4a54-4ec3-85e1-7bf3b82e4e5d",
   "metadata": {},
   "source": [
    "# match ROI ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c85a32e-47ee-4a7c-be92-1919b66d88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dict defines how to combine rois to full brain\n",
    "roi_sch_dict = {\n",
    "    'i3d_rgb-htROI': ['i3d_rgb_htROI5',\n",
    " 'i3d_rgb_htROI2',\n",
    " 'i3d_rgb_htROI6',\n",
    " 'i3d_rgb_htROI4',\n",
    " 'i3d_rgb_htROI3',\n",
    " 'i3d_rgb_htROI1'],\n",
    "    '3d_swin-htROI': ['3d_swin_htROI6',\n",
    " '3d_swin_htROI3',\n",
    " '3d_swin_htROI2',\n",
    " '3d_swin_htROI4',\n",
    " '3d_swin_htROI1',\n",
    " '3d_swin_htROI5'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "49270567-bb47-4895-aba8-1a090e9a77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_sch = 'H3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f981505-bbe4-42f8-a4dc-eeca0df21b58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae117662e41470aa1c2c5ff92b1acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 i3d_rgb_htROI5\n",
      "skipped existing ... H3 i3d_rgb_htROI2\n",
      "skipped existing ... H3 i3d_rgb_htROI6\n",
      "skipped existing ... H3 i3d_rgb_htROI4\n",
      "skipped existing ... H3 i3d_rgb_htROI3\n",
      "skipped existing ... H3 i3d_rgb_htROI1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61599fbc0bb466e945905a26a2f1227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped existing ... H3 3d_swin_htROI6\n",
      "skipped existing ... H3 3d_swin_htROI3\n",
      "skipped existing ... H3 3d_swin_htROI2\n",
      "skipped existing ... H3 3d_swin_htROI4\n",
      "skipped existing ... H3 3d_swin_htROI1\n",
      "skipped existing ... H3 3d_swin_htROI5\n"
     ]
    }
   ],
   "source": [
    "# X model\n",
    "for b in roi_sch_dict.keys():\n",
    "    backbone = b.replace('-htROI', '')\n",
    "    b_run_df = run_df[run_df['MODEL.BACKBONE.NAME'] == backbone]\n",
    "    \n",
    "    # Disk I/O is the bottle neck\n",
    "\n",
    "    verbose = True\n",
    "    opt_verbose = False\n",
    "    skip_existing = True\n",
    "    \n",
    "    rois = roi_sch_dict[b]\n",
    "    for roi in tqdm(rois[:]):\n",
    "        # skip existing files\n",
    "        path = roi_save_dir.joinpath(Path(f'backbone={backbone},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "        if path.exists():\n",
    "            if skip_existing:\n",
    "                print('skipped existing ...', he_sch, roi)\n",
    "                continue\n",
    "\n",
    "        roi_prediction = HEFN_REGISTRY[he_sch](b_run_df, roi, verbose=verbose, opt_verbose=opt_verbose)\n",
    "\n",
    "        torch.save(roi_prediction, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62e95774-1eda-4092-88ee-8726133d2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones = list(roi_sch_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9f60db5-aa95-4175-bb21-eab4552e30f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i3d_rgb-htROI', '3d_swin-htROI']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc31e4aa-97cc-4165-9d7f-f5b6babf84be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i3d_rgb-htROI': ['i3d_rgb_htROI5',\n",
       "  'i3d_rgb_htROI2',\n",
       "  'i3d_rgb_htROI6',\n",
       "  'i3d_rgb_htROI4',\n",
       "  'i3d_rgb_htROI3',\n",
       "  'i3d_rgb_htROI1'],\n",
       " '3d_swin-htROI': ['3d_swin_htROI6',\n",
       "  '3d_swin_htROI3',\n",
       "  '3d_swin_htROI2',\n",
       "  '3d_swin_htROI4',\n",
       "  '3d_swin_htROI1',\n",
       "  '3d_swin_htROI5']}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_sch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4ccc9db9-364b-427e-9074-ee0e6c9167e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.submission import algonauts2021_submission_from_whole_brain_prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afa8a107-433b-495b-8061-cce7d72ab90f",
   "metadata": {},
   "source": [
    "ls -Rltr /data/huze/ray_results/algonauts2021/notebook200/roi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e49c3df5-ca9b-4e5e-9fb8-def791e3d49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec6606b5d9d46c38c2c445cb17ebcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wb_shape = np.load(run_df.loc[run_df['DATASET.ROI'] == 'WB'].path.values[0].joinpath('prediction.npy')).shape\n",
    "\n",
    "for b in tqdm(backbones):\n",
    "    backbone = b.replace('-htROI', '')\n",
    "\n",
    "    for roi_sch, rois in roi_sch_dict.items():\n",
    "\n",
    "        prediction = torch.zeros(wb_shape)\n",
    "        \n",
    "        rois = roi_sch_dict[b]\n",
    "        \n",
    "        for roi in rois:\n",
    "            voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "            path = roi_save_dir.joinpath(Path(f'backbone={backbone},he_sch={he_sch},roi={roi}-prediction.pt'))\n",
    "            prediction[..., voxel_indices] = torch.load(path)\n",
    "\n",
    "        path = Path(os.path.join(save_dir, f'backbone={backbone},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "        torch.save(prediction, path)\n",
    "\n",
    "        # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "        #                                                 path.name.replace('-prediction.pt', ''),\n",
    "        #                                                 prediction[1000:].numpy(),\n",
    "        #                                                 output_dir='./submissions/full/',\n",
    "        #                                                 mini_track=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "266371c2-9e7b-443e-aeeb-9a3a0c25ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_roi_sch_dict_keys = list(all_combinations(['WB', 'aROI', 'htROI']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd73b137-2cd7-433d-96f9-e210411c3f6c",
   "metadata": {},
   "source": [
    "subset_roi_sch_dict_keys = list(itertools.combinations(list(roi_sch_dict.keys()), len(roi_sch_dict.keys())-1)) + [list(roi_sch_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "607b27a6-2355-4de2-bbe2-857dca60daa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WB',),\n",
       " ('aROI',),\n",
       " ('htROI',),\n",
       " ('WB', 'aROI'),\n",
       " ('WB', 'htROI'),\n",
       " ('aROI', 'htROI'),\n",
       " ('WB', 'aROI', 'htROI')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_roi_sch_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "778f4ba2-fd22-4397-a111-3095c7f0a8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i3d_rgb-htROI': ['i3d_rgb_htROI5',\n",
       "  'i3d_rgb_htROI2',\n",
       "  'i3d_rgb_htROI6',\n",
       "  'i3d_rgb_htROI4',\n",
       "  'i3d_rgb_htROI3',\n",
       "  'i3d_rgb_htROI1'],\n",
       " '3d_swin-htROI': ['3d_swin_htROI6',\n",
       "  '3d_swin_htROI3',\n",
       "  '3d_swin_htROI2',\n",
       "  '3d_swin_htROI4',\n",
       "  '3d_swin_htROI1',\n",
       "  '3d_swin_htROI5']}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_sch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "efd86998-6a27-428a-ba7b-84a5e11fe128",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_sch_dict_full = roi_sch_dict\n",
    "roi_sch_dict_full.update({\n",
    "    'WB': ['WB'],\n",
    "    'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7bd1253d-a45c-4b20-9431-38dcd39f0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'WB': ['WB']}, {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']}, {'i3d_rgb-htROI': ['i3d_rgb_htROI5', 'i3d_rgb_htROI2', 'i3d_rgb_htROI6', 'i3d_rgb_htROI4', 'i3d_rgb_htROI3', 'i3d_rgb_htROI1']}, {'WB': ['WB'], 'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']}, {'WB': ['WB'], 'i3d_rgb-htROI': ['i3d_rgb_htROI5', 'i3d_rgb_htROI2', 'i3d_rgb_htROI6', 'i3d_rgb_htROI4', 'i3d_rgb_htROI3', 'i3d_rgb_htROI1']}, {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'], 'i3d_rgb-htROI': ['i3d_rgb_htROI5', 'i3d_rgb_htROI2', 'i3d_rgb_htROI6', 'i3d_rgb_htROI4', 'i3d_rgb_htROI3', 'i3d_rgb_htROI1']}, {'WB': ['WB'], 'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'], 'i3d_rgb-htROI': ['i3d_rgb_htROI5', 'i3d_rgb_htROI2', 'i3d_rgb_htROI6', 'i3d_rgb_htROI4', 'i3d_rgb_htROI3', 'i3d_rgb_htROI1']}]\n",
      "[{'WB': ['WB']}, {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']}, {'3d_swin-htROI': ['3d_swin_htROI6', '3d_swin_htROI3', '3d_swin_htROI2', '3d_swin_htROI4', '3d_swin_htROI1', '3d_swin_htROI5']}, {'WB': ['WB'], 'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']}, {'WB': ['WB'], '3d_swin-htROI': ['3d_swin_htROI6', '3d_swin_htROI3', '3d_swin_htROI2', '3d_swin_htROI4', '3d_swin_htROI1', '3d_swin_htROI5']}, {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'], '3d_swin-htROI': ['3d_swin_htROI6', '3d_swin_htROI3', '3d_swin_htROI2', '3d_swin_htROI4', '3d_swin_htROI1', '3d_swin_htROI5']}, {'WB': ['WB'], 'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'], '3d_swin-htROI': ['3d_swin_htROI6', '3d_swin_htROI3', '3d_swin_htROI2', '3d_swin_htROI4', '3d_swin_htROI1', '3d_swin_htROI5']}]\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    subset_roi_sch_dicts = []\n",
    "    for keys in subset_roi_sch_dict_keys:\n",
    "        d = {k if k != 'htROI' else backbone: roi_sch_dict_full[k if k != 'htROI' else backbone] for k in keys}\n",
    "        subset_roi_sch_dicts.append(d)\n",
    "    print(subset_roi_sch_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "263e92ac-02be-4dd4-b5be-9adc520cd5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'WB': ['WB']},\n",
       " {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']},\n",
       " {'3d_swin-htROI': ['3d_swin_htROI6',\n",
       "   '3d_swin_htROI3',\n",
       "   '3d_swin_htROI2',\n",
       "   '3d_swin_htROI4',\n",
       "   '3d_swin_htROI1',\n",
       "   '3d_swin_htROI5']},\n",
       " {'WB': ['WB'],\n",
       "  'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST']},\n",
       " {'WB': ['WB'],\n",
       "  '3d_swin-htROI': ['3d_swin_htROI6',\n",
       "   '3d_swin_htROI3',\n",
       "   '3d_swin_htROI2',\n",
       "   '3d_swin_htROI4',\n",
       "   '3d_swin_htROI1',\n",
       "   '3d_swin_htROI5']},\n",
       " {'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
       "  '3d_swin-htROI': ['3d_swin_htROI6',\n",
       "   '3d_swin_htROI3',\n",
       "   '3d_swin_htROI2',\n",
       "   '3d_swin_htROI4',\n",
       "   '3d_swin_htROI1',\n",
       "   '3d_swin_htROI5']},\n",
       " {'WB': ['WB'],\n",
       "  'aROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
       "  '3d_swin-htROI': ['3d_swin_htROI6',\n",
       "   '3d_swin_htROI3',\n",
       "   '3d_swin_htROI2',\n",
       "   '3d_swin_htROI4',\n",
       "   '3d_swin_htROI1',\n",
       "   '3d_swin_htROI5']}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_roi_sch_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2701a356-9359-409d-8559-8e7e5fd49474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb11bf03b064014ade1229cf8fd65f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=i3d_rgb:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3d_rgb WB 0.45329281106712116\n",
      "i3d_rgb aROI 0.45329281106712116\n",
      "i3d_rgb i3d_rgb-htROI 0.45329281106712116\n",
      "i3d_rgb WB+aROI 0.45329281106712116\n",
      "i3d_rgb WB+i3d_rgb-htROI 0.45329281106712116\n",
      "i3d_rgb aROI+i3d_rgb-htROI 0.45329281106712116\n",
      "i3d_rgb WB+aROI+i3d_rgb-htROI 0.45329281106712116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea576e1b65042fb9cecfff8f7ec0884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d_swin WB 0.45329281106712116\n",
      "3d_swin aROI 0.45329281106712116\n",
      "3d_swin 3d_swin-htROI 0.45329281106712116\n",
      "3d_swin WB+aROI 0.45329281106712116\n",
      "3d_swin WB+3d_swin-htROI 0.45329281106712116\n",
      "3d_swin aROI+3d_swin-htROI 0.45329281106712116\n",
      "3d_swin WB+aROI+3d_swin-htROI 0.45329281106712116\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    \n",
    "    backbone = backbone.replace('-htROI', '')\n",
    "    \n",
    "    subset_roi_sch_dicts = []\n",
    "    for keys in subset_roi_sch_dict_keys:\n",
    "        d = {k if k != 'htROI' else backbone+'-htROI': roi_sch_dict_full[k if k != 'htROI' else backbone+'-htROI'] for k in keys}\n",
    "        subset_roi_sch_dicts.append(d)\n",
    "\n",
    "    for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                   desc=f'backbone={backbone}'):\n",
    "        subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "        intersection_sch = 'grouped ensemble'\n",
    "\n",
    "        wb_shape = None\n",
    "        new_prediction = None\n",
    "        \n",
    "        prediction_list = [torch.load(os.path.join(save_dir,\n",
    "                         f'backbone={backbone},he_sch={he_sch},roi_sch={roi_sch}-prediction.pt'))\n",
    "                   for roi_sch in subset_roi_sch_dict.keys()]\n",
    "        \n",
    "        if len(prediction_list) > 1:\n",
    "        \n",
    "            for rois in list(itertools.product(*subset_roi_sch_dict.values())):\n",
    "                voxel_indices_list = [torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt')) for roi in rois]\n",
    "                intersect = intersect1d_multi_arr(voxel_indices_list)\n",
    "\n",
    "                if wb_shape is None: wb_shape = prediction_list[0].shape\n",
    "                if new_prediction is None: new_prediction = torch.zeros(wb_shape)\n",
    "\n",
    "                intersect_prediction_list = [p[:, intersect] for p in prediction_list]\n",
    "\n",
    "                if len(intersect) > 0:\n",
    "                    new_prediction[:, intersect] = INTFN_REGISTRY[intersection_sch](intersect_prediction_list, val_indices, val_fmris[:, intersect])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            new_prediction = prediction_list[0]\n",
    "        \n",
    "        path = Path(os.path.join(save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-prediction.pt'))\n",
    "        \n",
    "        torch.save(new_prediction, path)\n",
    "        \n",
    "        # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "        #                                                 path.name.replace('-prediction.pt', ''),\n",
    "        #                                                 new_prediction[1000:].numpy(),\n",
    "        #                                                 output_dir='./submissions/ablation/',\n",
    "        #                                                 mini_track=False)\n",
    "        scores = vectorized_correlation(new_prediction[val_indices], val_fmris) / noise_ceiling\n",
    "        score = scores.mean().item()\n",
    "        print(backbone, subset_roi_sch_text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5621c36c-1064-4500-b47b-db17a6af9901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28ad2b4e8644daaba4313e0efdb71f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=i3d_rgb:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3d_rgb WB \t 0.42381963992639043 \t 0.0012802009652976766\n",
      "i3d_rgb aROI \t 0.44165807653587275 \t 0.001294845655740069\n",
      "i3d_rgb i3d_rgb-htROI \t 0.4587858653969395 \t 0.0012912800939623194\n",
      "i3d_rgb WB+aROI \t 0.44480154283773893 \t 0.0012980887036060397\n",
      "i3d_rgb WB+i3d_rgb-htROI \t 0.4672036128227344 \t 0.001295391605606082\n",
      "i3d_rgb aROI+i3d_rgb-htROI \t 0.47562842784751 \t 0.001301372850536858\n",
      "i3d_rgb WB+aROI+i3d_rgb-htROI \t 0.4759140821714593 \t 0.00130205356500629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e6b6fef8cd48e586bc543714c3a20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backbone=3d_swin:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d_swin WB \t 0.4258591710305511 \t 0.001284256608850363\n",
      "3d_swin aROI \t 0.43825530491334425 \t 0.001299097228986688\n",
      "3d_swin 3d_swin-htROI \t 0.4500680052811477 \t 0.0012835251018083217\n",
      "3d_swin WB+aROI \t 0.4418752167942003 \t 0.0012999066120577252\n",
      "3d_swin WB+3d_swin-htROI \t 0.4575968953670858 \t 0.0012909982856360834\n",
      "3d_swin aROI+3d_swin-htROI \t 0.4624340316515358 \t 0.0012973117182602093\n",
      "3d_swin WB+aROI+3d_swin-htROI \t 0.46343147739444684 \t 0.0012975150455865516\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    \n",
    "    backbone = backbone.replace('-htROI', '')\n",
    "    \n",
    "    subset_roi_sch_dicts = []\n",
    "    for keys in subset_roi_sch_dict_keys:\n",
    "        d = {k if k != 'htROI' else backbone+'-htROI': roi_sch_dict_full[k if k != 'htROI' else backbone+'-htROI'] for k in keys}\n",
    "        subset_roi_sch_dicts.append(d)\n",
    "\n",
    "    for subset_roi_sch_dict in tqdm(subset_roi_sch_dicts,\n",
    "                                   desc=f'backbone={backbone}'):\n",
    "        subset_roi_sch_text = '+'.join(subset_roi_sch_dict.keys())\n",
    "        intersection_sch = 'grouped ensemble'\n",
    "        \n",
    "        path = Path(os.path.join(save_dir,\n",
    "                                     f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                     f'-prediction.pt'))\n",
    "        \n",
    "        new_prediction = torch.load(path)\n",
    "        \n",
    "        # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "        #                                                 path.name.replace('-prediction.pt', ''),\n",
    "        #                                                 new_prediction[1000:].numpy(),\n",
    "        #                                                 output_dir='./submissions/ablation/',\n",
    "        #                                                 mini_track=False)\n",
    "        scores = vectorized_correlation(new_prediction[val_indices], val_fmris) / noise_ceiling\n",
    "        sem = scores.std() / np.sqrt(len(scores))\n",
    "        sem = sem.item()\n",
    "        score = scores.mean().item()\n",
    "        print(backbone, subset_roi_sch_text, '\\t', score, '\\t', sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "20a72bd2-6f18-4580-884d-d8f0e481874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3d_rgb WB+aROI+S-htROI \t 0.4776067037549395 \t 0.0013163660471815686\n",
      "3d_swin WB+aROI+S-htROI \t 0.4685314330434128 \t 0.0013100570368334515\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    backbone = backbone.replace('-htROI', '')\n",
    "    \n",
    "    he_sch = 'H3'\n",
    "    subset_roi_sch_text = 'WB+aROI+S-htROI'\n",
    "    intersection_sch = 'grouped ensemble'\n",
    "\n",
    "        \n",
    "    path = Path(os.path.join(save_dir,\n",
    "                                 f'backbone={backbone},he_sch={he_sch},intersection_sch={intersection_sch},subset_roi_sch={subset_roi_sch_text}'\n",
    "                                 f'-prediction.pt'))\n",
    "        \n",
    "    new_prediction = torch.load(path)\n",
    "        \n",
    "    # algonauts2021_submission_from_whole_brain_prediction('../../src/config/dataset',\n",
    "    #                                                 path.name.replace('-prediction.pt', ''),\n",
    "    #                                                 new_prediction[1000:].numpy(),\n",
    "    #                                                 output_dir='./submissions/ablation/',\n",
    "    #                                                 mini_track=False)\n",
    "    scores = vectorized_correlation(new_prediction[val_indices], val_fmris) / noise_ceiling\n",
    "    sem = scores.std() / np.sqrt(len(scores))\n",
    "    sem = sem.item()\n",
    "    score = scores.mean().item()\n",
    "    print(backbone, subset_roi_sch_text, '\\t', score, '\\t', sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2ee00-ebfd-453f-b92a-31038e926be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0c814-1ca4-4450-89b8-708a95592560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0f153-50d6-4e44-81ef-5d83ad0e9bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02feab8a-8012-4e8b-9ce7-865c4cc61c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4af5b862-ef7e-4873-bb73-b4fb53dd9b86",
   "metadata": {},
   "source": [
    "# count GPU time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58e0e28c-2cce-46b8-ae06-a5fd366293d3",
   "metadata": {},
   "source": [
    "res_dicts = []\n",
    "for model_sch in model_schs:\n",
    "    df = model_sch_dfs[model_sch]\n",
    "    \n",
    "    res_dict = {'model_sch': model_sch}\n",
    "    for roi in df['DATASET.ROI'].unique():\n",
    "        roi_df = df[df['DATASET.ROI'] == roi]\n",
    "        time_sum = roi_df.time.sum() / 3600\n",
    "        res_dict[roi] = time_sum\n",
    "    res_dicts.append(res_dict)\n",
    "time_df = pd.DataFrame(res_dicts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "802a4283-b480-4ebb-b936-d4d823a8848d",
   "metadata": {},
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55358263-662e-4949-af6b-12a5067054db",
   "metadata": {},
   "source": [
    "for model_sch in time_df.model_sch.unique():\n",
    "    if '+' in model_sch:\n",
    "        continue\n",
    "    \n",
    "    for roi_sch, roi_sch_rois in roi_sch_dict.items():\n",
    "        if roi_sch not in ['ROI', 'SMC']:\n",
    "            continue\n",
    "        time_sum = time_df[time_df['model_sch'] == model_sch][roi_sch_rois].values.sum()\n",
    "        print(*model_sch.split('&'), roi_sch, f'{time_sum:.2f}h')\n",
    "    time_sum = time_df[time_df['model_sch'] == model_sch][['WB']].values.sum()\n",
    "    print(*model_sch.split('&'), 'WB', f'{time_sum:.2f}h')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0df47064-c844-4c6d-8aff-58d2f370fe69",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
