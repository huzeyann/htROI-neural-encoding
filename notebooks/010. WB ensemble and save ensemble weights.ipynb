{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37988c-55a7-4d41-b089-5fc040a6b681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a99c81a-47ce-4e99-80bc-767e73013ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d18740-a16e-4d35-94eb-2b36f97762f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836d6132-a5dc-45bd-bfa1-c7c1f4a940df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir /data/huze/ray_results/algonauts2021\n"
     ]
    }
   ],
   "source": [
    "# results_dir = Path(os.getenv('RESULTS_DIR'))\n",
    "results_dir = Path('/data/huze/ray_results/algonauts2021')\n",
    "print('results_dir', results_dir)\n",
    "\n",
    "finished_runs = [path.parent for path in results_dir.glob('**/prediction.npy')]\n",
    "# print('finished_runs', len(finished_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d136d9c3-31c6-4dda-a76c-6e0ff3e8a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['params.pkl',\n",
      " 'voxel_embedding.npy',\n",
      " 'result.json',\n",
      " 'hparams.yaml',\n",
      " 'events.out.tfevents.1645601235.yfwu-guslab',\n",
      " 'params.json',\n",
      " 'progress.csv',\n",
      " 'prediction.npy',\n",
      " 'events.out.tfevents.1645601256.yfwu-guslab.3793893.0']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "exapmle_files = list(path.name for path in finished_runs[0].iterdir())\n",
    "pprint(exapmle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98f6d8c-3822-458a-9ffe-7ea454d01f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b57ed12180d4ebfad35addd6ce18f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total GPU time 279.05h\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from yaml import CLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "from src.config.config import flatten\n",
    "\n",
    "finished_runs = [path.parent for path in results_dir.glob('**/prediction.npy')]\n",
    "\n",
    "run_meta_infos = []\n",
    "for run_dir in tqdm(finished_runs):\n",
    "    hparams = yaml.load(run_dir.joinpath('hparams.yaml').open(), Loader=CLoader)\n",
    "    run_meta_info = flatten(hparams)\n",
    "    run_meta_info['path'] = run_dir\n",
    "\n",
    "    data = [json.loads(line) for line in run_dir.joinpath('result.json').open()]\n",
    "    ddf = pd.DataFrame(data)\n",
    "    run_meta_info['score'] = ddf.val_corr.max()\n",
    "    run_meta_info['time'] = ddf.time_total_s.max()\n",
    "\n",
    "    run_meta_infos.append(run_meta_info)\n",
    "\n",
    "run_df = pd.DataFrame(run_meta_infos)\n",
    "\n",
    "# fix list unhashable\n",
    "run_df['MODEL.BACKBONE.LAYERS'] = run_df['MODEL.BACKBONE.LAYERS'].apply(lambda x: tuple(x))\n",
    "run_df['MODEL.NECK.SPP_LEVELS'] = run_df['MODEL.NECK.SPP_LEVELS'].apply(lambda x: tuple(x))\n",
    "\n",
    "print(f'total GPU time {run_df.time.sum() / 3600:.2f}h')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5357a6c1-7fe4-442a-a1e8-96b95c12aaf7",
   "metadata": {},
   "source": [
    "pprint(run_meta_info)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f17b7b5f-6a8f-4559-adf4-f8fae587319c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "run_df[(run_df['MODEL.BACKBONE.NAME'].isin(['i3d_rgb', 'i3d_flow']))&\n",
    "       (run_df['MODEL.NECK.SPP_LEVELS'] == (2, )) &\n",
    "       (run_df['DATASET.ROI'] == 'WB')][\n",
    "    ['MODEL.BACKBONE.NAME', 'DATASET.ROI', 'MODEL.BACKBONE.LAYERS', 'MODEL.NECK.SPP_LEVELS', 'score']].sort_values('DATASET.ROI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5ac4c-8c2a-4924-bb13-4aae03e2bd7a",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5f6ec5-363a-44ca-8bc9-59c4d0784948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ensemble import optimize_val_correlation\n",
    "from src.config.config import combine_cfgs, get_cfg_defaults\n",
    "from src.data.datamodule import MyDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c18ed3d-7be6-4fef-9d3a-c83417b76c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "cfg = combine_cfgs('../src/config/experiments/algonauts2021_i3d_flow.yml')\n",
    "dm = MyDataModule(cfg)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "val_indices = dm.val_dataset.indices\n",
    "\n",
    "cache_path = Path('/data_smr/huze/.cache/val_fmris.pt')\n",
    "\n",
    "if cache_path.exists():\n",
    "    val_fmris = torch.load(cache_path)\n",
    "else:\n",
    "    val_fmris = [dm.dataset_train_val.__getitem__(i)[1] for i in tqdm(val_indices)]\n",
    "    val_fmris = np.stack(val_fmris, 0)\n",
    "    val_fmris = torch.tensor(val_fmris)\n",
    "    torch.save(val_fmris, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a3d2404c-adfe-404d-9b35-8f4f0dbf904a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ensemble_prediction_from_tensor_list(predicions_list, roi_val_fmris, val_indices, opt_verbose=False):\n",
    "    predictions = torch.stack(predicions_list, -1)\n",
    "    ws = optimize_val_correlation(predictions,\n",
    "                                  roi_val_fmris,\n",
    "                                  verbose=opt_verbose,\n",
    "                                  device=DEVICE)\n",
    "    new_predictions = predictions @ ws\n",
    "    return new_predictions, ws\n",
    "\n",
    "def multiply_and_flatten_voxel_embeddings_by_ensemble_weight(voxel_embeddings_list, ws, voxel_embeddings_dims=2, cat_dim=-1):\n",
    "    for i in range(len(ws)):\n",
    "        voxel_embeddings_list[i] *= ws[i]\n",
    "    \n",
    "    if len(voxel_embeddings_list[0].shape) == voxel_embeddings_dims:\n",
    "        return torch.stack(voxel_embeddings_list, cat_dim)\n",
    "    elif len(voxel_embeddings_list[0].shape) == voxel_embeddings_dims + 1:\n",
    "        return torch.cat(voxel_embeddings_list, cat_dim)\n",
    "    else:\n",
    "        NotImplementedError()\n",
    "        \n",
    "def multiply_and_flatten_ensemble_weights(previous_ws_list, ws, ws_dim=1, cat_dim=0):\n",
    "    for i in range(len(ws)):\n",
    "        voxel_embeddings_list[i] *= ws[i]\n",
    "    \n",
    "    if len(voxel_embeddings_list[0].shape) == voxel_embeddings_dims:\n",
    "        return torch.stack(voxel_embeddings_list, cat_dim)\n",
    "    elif len(voxel_embeddings_list[0].shape) == voxel_embeddings_dims + 1:\n",
    "        return torch.cat(voxel_embeddings_list, cat_dim)\n",
    "    else:\n",
    "        NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4463b2-c96d-4e91-a192-418c6e1574d6",
   "metadata": {},
   "source": [
    "# 3 level of hierarchical ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5c04bd75-7b0f-40b6-9fa6-acb8470fb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = 'V1'\n",
    "verbose=True\n",
    "opt_verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e1352b1b-d915-421b-827b-6fb639cf2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do ensemble, but not load voxel_embedding.npy\n",
    "# this part should run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18ca049a-ec43-47e5-be4c-bebf598cb0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1...\t WB i3d_rgb ('x3',) \t\n",
      "Level 1...\t WB i3d_rgb ('x2',) \t\n",
      "Level 1...\t WB i3d_rgb ('x4',) \t\n",
      "Level 1...\t WB i3d_rgb ('x1',) \t\n",
      "Level 1...\t WB i3d_rgb ('x1', 'x2', 'x3') \t\n",
      "Level 1...\t WB i3d_rgb ('x1', 'x2', 'x3', 'x4') \t\n",
      "Level 1...\t WB i3d_rgb ('x2', 'x3', 'x4') \t\n",
      "Level 2...\t WB i3d_rgb \t\n",
      "Level 1...\t WB i3d_flow ('x3',) \t\n",
      "Level 1...\t WB i3d_flow ('x2',) \t\n",
      "Level 1...\t WB i3d_flow ('x4',) \t\n",
      "Level 1...\t WB i3d_flow ('x1',) \t\n",
      "Level 1...\t WB i3d_flow ('x1', 'x2', 'x3') \t\n",
      "Level 1...\t WB i3d_flow ('x1', 'x2', 'x3', 'x4') \t\n",
      "Level 1...\t WB i3d_flow ('x2', 'x3', 'x4') \t\n",
      "Level 2...\t WB i3d_flow \t\n",
      "Level 3...\t WB \t\n"
     ]
    }
   ],
   "source": [
    "from src.utils.misc import my_query_df\n",
    "\n",
    "ORDERED_HIERACHY_KEYS = ['MODEL.BACKBONE.NAME', 'MODEL.BACKBONE.LAYERS', 'MODEL.NECK.SPP_LEVELS']\n",
    "he_keys=ORDERED_HIERACHY_KEYS\n",
    "    \n",
    "# assert roi == 'WB' # comment this line to subdivide other rois\n",
    "\n",
    "avaliable_configs = list(run_df.groupby(he_keys[:2]).groups)\n",
    "\n",
    "roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "\n",
    "level1_config_tasks_ws = []\n",
    "level2_config_ws = []\n",
    "level3_ws = []\n",
    "\n",
    "oo_predictions_list = []\n",
    "# oo_voxel_embeddings_list = []\n",
    "oo_ws_list = []\n",
    "for v11 in run_df[he_keys[0]].unique():\n",
    "    o_predictions_list = []\n",
    "    # o_voxel_embeddings_list = []\n",
    "    o_ws_list = []\n",
    "    for v1 in run_df[he_keys[1]].unique():\n",
    "\n",
    "        vs = (v11, v1)\n",
    "        if vs not in avaliable_configs: continue\n",
    "        _l1_df = my_query_df(run_df, equal_dict={k: v for k, v in zip(he_keys[:2], vs)})\n",
    "        roi_df = _l1_df.loc[_l1_df['DATASET.ROI'] == roi]\n",
    "\n",
    "        predictions_list = [\n",
    "            torch.tensor(np.load(path.joinpath('prediction.npy'))).float()[val_indices]\n",
    "            for path in roi_df['path'].values\n",
    "        ]\n",
    "\n",
    "        # voxel_embeddings_list = [\n",
    "        #     torch.tensor(np.load(path.joinpath('voxel_embedding.npy')))\n",
    "        #     for path in roi_df['path'].values\n",
    "        # ]\n",
    "\n",
    "        if verbose:\n",
    "            print('Level 1...\\t', roi, v11, v1, '\\t')\n",
    "        new_predictions, ws = get_ensemble_prediction_from_tensor_list(predictions_list, roi_val_fmris, val_indices, opt_verbose=opt_verbose)\n",
    "        # new_voxel_embeddings = multiply_and_flatten_voxel_embeddings_by_ensemble_weight(voxel_embeddings_list, ws)\n",
    "        \n",
    "        level1_config_tasks_ws.append((vs, roi_df['path'].values, ws.numpy()))\n",
    "\n",
    "        o_predictions_list.append(new_predictions)\n",
    "        # o_voxel_embeddings_list.append(new_voxel_embeddings)\n",
    "        o_ws_list.append(ws)\n",
    "    if verbose:\n",
    "        print('Level 2...\\t', roi, v11, '\\t')\n",
    "    new_predictions, ws = get_ensemble_prediction_from_tensor_list(o_predictions_list, roi_val_fmris, val_indices, opt_verbose=opt_verbose)\n",
    "    # new_voxel_embeddings = multiply_and_flatten_voxel_embeddings_by_ensemble_weight(o_voxel_embeddings_list, ws)\n",
    "\n",
    "    level2_config_ws.append((v11, ws.numpy()))\n",
    "\n",
    "    oo_predictions_list.append(new_predictions)\n",
    "    # oo_voxel_embeddings_list.append(new_voxel_embeddings)\n",
    "    assert len(ws) == len(o_ws_list)\n",
    "    for i in range(len(ws)):\n",
    "        o_ws_list[i] *= ws[i]\n",
    "    oo_ws_list.append(torch.cat(o_ws_list))\n",
    "if verbose:\n",
    "    print('Level 3...\\t', roi, '\\t')\n",
    "new_predictions, ws = get_ensemble_prediction_from_tensor_list(oo_predictions_list, roi_val_fmris, val_indices, opt_verbose=opt_verbose)\n",
    "# new_voxel_embeddings = multiply_and_flatten_voxel_embeddings_by_ensemble_weight(oo_voxel_embeddings_list, ws)\n",
    "\n",
    "level3_ws.append(ws.numpy())\n",
    "\n",
    "assert len(ws) == len(oo_ws_list)\n",
    "for i in range(len(ws)):\n",
    "    oo_ws_list[i] *= ws[i]\n",
    "full_ws = torch.cat(oo_ws_list)\n",
    "\n",
    "# voxel_embeddings_dict = {k: v for k, v in zip(run_df[he_keys[0]].unique(), oo_voxel_embeddings_list)}\n",
    "\n",
    "# voxel_embeddings_dict['all'] = new_voxel_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3e8cd9c5-23dc-4907-8883-2ef3961ff3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(full_ws, 'tmp/ensemble_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54f483-2ce3-4851-804b-0c3714f9e41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
