{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eed0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b47456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a6eb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/huze/ray_results/algonauts2021\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(os.getenv('RESULTS_DIR'))\n",
    "print(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b342bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "finished_runs = [path.parent for path in results_dir.glob('**/prediction.npy')]\n",
    "print(len(finished_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e477156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['params.json',\n",
      " 'events.out.tfevents.1645454949.yfwu-guslab.2544995.0',\n",
      " 'progress.csv',\n",
      " 'result.json',\n",
      " 'hparams.yaml',\n",
      " 'events.out.tfevents.1645454934.yfwu-guslab',\n",
      " 'prediction.npy',\n",
      " 'voxel_embedding.npy',\n",
      " 'params.pkl']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "exapmle_files = list(path.name for path in finished_runs[0].iterdir())\n",
    "pprint(exapmle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6768820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml import CLoader\n",
    "\n",
    "from src.config.config import flatten\n",
    "\n",
    "run_meta_infos = []\n",
    "for run_dir in finished_runs:\n",
    "    hparams = yaml.load(run_dir.joinpath('hparams.yaml').open(), Loader=CLoader)\n",
    "    run_meta_info = flatten(hparams)\n",
    "    run_meta_info['path'] = run_dir\n",
    "    run_meta_infos.append(run_meta_info)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "run_df = pd.DataFrame(run_meta_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa2b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "07a61056",
   "metadata": {},
   "source": [
    "pprint(run_meta_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1073c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68d60c4c",
   "metadata": {},
   "source": [
    "# hierarchical ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b310bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ensemble import optimize_val_correlation\n",
    "from src.config.config import combine_cfgs, get_cfg_defaults\n",
    "from src.data.datamodule import MyDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ca5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "cfg = combine_cfgs('../src/config/experiments/algonauts2021_i3d_flow.yml')\n",
    "dm = MyDataModule(cfg)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "val_indices = dm.val_dataset.indices\n",
    "\n",
    "cache_path = Path('/home/huze/.cache/val_fmris.pt')\n",
    "\n",
    "if cache_path.exists():\n",
    "    val_fmris = torch.load(cache_path)\n",
    "else:\n",
    "    val_fmris = [dm.dataset_train_val.__getitem__(i) for i in tqdm(val_indices)]\n",
    "    val_fmris = np.stack(val_fmris, 0)\n",
    "    val_fmris = torch.tensor(val_fmris)\n",
    "    torch.save(val_fmris, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981b7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis grid search space\n",
    "rois = run_df['DATASET.ROI'].unique()\n",
    "backbones = run_df['MODEL.BACKBONE.NAME'].unique()\n",
    "configs = list(itertools.product(*[run_df[k].unique() for k in ['MODEL.BACKBONE.LAYERS', 'MODEL.NECK.SPP_LEVELS']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical ensemble\n",
    "verbose = True\n",
    "opt_verbose = False\n",
    "\n",
    "roi_predictoin_dict = {}\n",
    "roi_voxel_indices_dict = {}\n",
    "\n",
    "for roi in rois:\n",
    "    if roi == 'WB':\n",
    "        # WB model is already in `level1` below\n",
    "        continue\n",
    "    \n",
    "    # load flattened voxel masks\n",
    "    roi_voxel_indices = torch.load(os.path.join(cfg.DATASET.VOXEL_INDEX_DIR, f'{roi}.pt'))\n",
    "    roi_voxel_indices_dict[roi] = roi_voxel_indices\n",
    "    roi_val_fmris = val_fmris[..., roi_voxel_indices]\n",
    "    \n",
    "    l3_predictions = []\n",
    "    # level3 combine different models\n",
    "    for backbone in backbones:\n",
    "        l2_predictions = []\n",
    "        # level2 combine all layers and pooling sche\n",
    "        for layers, spp_levels in configs:\n",
    "            # level1 roi_model + wb_model\n",
    "            _l1_df = run_df.loc[\n",
    "                (run_df['MODEL.BACKBONE.NAME'] == backbone) &\n",
    "                (run_df['MODEL.BACKBONE.LAYERS'] == layers) &\n",
    "                (run_df['MODEL.NECK.SPP_LEVELS'] == spp_levels)\n",
    "            ]\n",
    "            roi_l1_df = _l1_df.loc[_l1_df['DATASET.ROI'] == roi]\n",
    "            wb_l1_df = _l1_df.loc[_l1_df['DATASET.ROI'] == 'WB']\n",
    "            \n",
    "            # 1 ROI model pair with 1 WB model, with the same hyperparameter\n",
    "            # if not paired (grid run is not complete yet), will skip\n",
    "            if not (len(roi_l1_df) == 1 and len(wb_l1_df) == 1):\n",
    "                print('skipped...\\t', roi, backbone, layers, spp_levels, '\\t',\n",
    "                      f'roi={len(roi_l1_df)}', f'wb={len(wb_l1_df)}')\n",
    "                continue\n",
    "            if verbose:\n",
    "                print('Level 1...\\t', roi, backbone, layers, spp_levels, '\\t')\n",
    "            l1_predictions = np.stack([\n",
    "                np.load(roi_l1_df['path'].item().joinpath('prediction.npy')),\n",
    "                np.load(wb_l1_df['path'].item().joinpath('prediction.npy'))[..., roi_voxel_indices],\n",
    "            ], -1)\n",
    "            l1_predictions = torch.tensor(l1_predictions).float()\n",
    "            l1_ensemble_weight = optimize_val_correlation(l1_predictions[val_indices].clone(), \n",
    "                                                          roi_val_fmris.clone(), \n",
    "                                                          verbose=opt_verbose,\n",
    "                                                         device=0)\n",
    "            new_predictions = l1_predictions @ l1_ensemble_weight\n",
    "            l2_predictions.append(new_predictions)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Level 2...\\t', roi, backbone, '\\t')\n",
    "        l2_predictions = torch.stack(l2_predictions, -1)\n",
    "        l2_ensemble_weight = optimize_val_correlation(l2_predictions[val_indices].clone(), \n",
    "                                                          roi_val_fmris.clone(), \n",
    "                                                          verbose=opt_verbose,\n",
    "                                                         device=0)\n",
    "        new_predictions = l2_predictions @ l2_ensemble_weight\n",
    "        l3_predictions.append(new_predictions)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Level 3...\\t', roi, '\\t')\n",
    "    l3_predictions = torch.stack(l3_predictions, -1)\n",
    "    l3_ensemble_weight = optimize_val_correlation(l3_predictions[val_indices].clone(), \n",
    "                                                      roi_val_fmris.clone(), \n",
    "                                                      verbose=opt_verbose,\n",
    "                                                     device=0)\n",
    "    \n",
    "    roi_prediction = l3_predictions @ l3_ensemble_weight\n",
    "    \n",
    "    roi_predictoin_dict[roi] = roi_prediction\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9162c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "358e0a72",
   "metadata": {},
   "source": [
    "# \"emsemble\" ROIs to full brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d31d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dict = {\n",
    "    'ROI': ['V1', 'V2', 'V3', 'V4', 'EBA', 'LOC', 'PPA', 'FFA', 'STS', 'REST'],\n",
    "    'LC': ['LC1', 'LC2', 'LC3', 'LC4', 'LC5'],\n",
    "    'MC': ['MC1', 'MC2', 'LC2', 'LC3', 'LC4', 'LC5'],\n",
    "    'SMC': ['SMC1', 'SMC2', 'MC2', 'LC2', 'LC3', 'LC4', 'LC5'],\n",
    "    'SC': ['SMC1', 'SMC2', 'SC3', 'SC4', 'LC2', 'LC3', 'LC4', 'LC5'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba32909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 161326)\n"
     ]
    }
   ],
   "source": [
    "shape = np.load(run_df.loc[run_df['DATASET.ROI'] == 'WB'].path.values[0].joinpath('prediction.npy')).shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "642b8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine rois to full brain\n",
    "sch_prediction_dict = {}\n",
    "for sch_name, sch_rois in combine_dict.items():\n",
    "    prediction = torch.zeros(shape)\n",
    "    for roi in sch_rois:\n",
    "        voxel_indices = roi_voxel_indices_dict[roi]\n",
    "        prediction[..., voxel_indices] = roi_predictoin_dict[roi]\n",
    "    sch_prediction_dict[sch_name] = prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc88ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROI': tensor([[-0.0479,  0.0272,  0.0302,  ..., -0.0647, -0.1650, -0.0747],\n",
       "         [ 0.0115, -0.0449, -0.0573,  ..., -0.1238, -0.1307,  0.0253],\n",
       "         [-0.0059,  0.0199, -0.0389,  ...,  0.0397,  0.1095,  0.0897],\n",
       "         ...,\n",
       "         [ 0.0478,  0.0042, -0.0398,  ...,  0.0993,  0.2024,  0.1934],\n",
       "         [-0.0636,  0.0524,  0.0418,  ..., -0.0578, -0.1556, -0.1591],\n",
       "         [-0.0236,  0.0208,  0.0106,  ...,  0.0794,  0.1082,  0.0487]]),\n",
       " 'LC': tensor([[-0.0454,  0.0734,  0.0509,  ..., -0.0268, -0.1024, -0.0553],\n",
       "         [ 0.0129, -0.0925, -0.1032,  ..., -0.0210, -0.0207,  0.0889],\n",
       "         [ 0.0127,  0.0100, -0.0492,  ...,  0.0776,  0.1567,  0.1396],\n",
       "         ...,\n",
       "         [ 0.0224, -0.0102, -0.0404,  ...,  0.1298,  0.2577,  0.2563],\n",
       "         [-0.0426,  0.0466,  0.0378,  ..., -0.0542, -0.1925, -0.2289],\n",
       "         [-0.0333, -0.0183, -0.0183,  ...,  0.0332,  0.0778,  0.0940]]),\n",
       " 'MC': tensor([[-0.0412,  0.0834,  0.0535,  ..., -0.0268, -0.1024, -0.0553],\n",
       "         [ 0.0378, -0.0595, -0.0714,  ..., -0.0210, -0.0207,  0.0889],\n",
       "         [ 0.0098, -0.0158, -0.0510,  ...,  0.0776,  0.1567,  0.1396],\n",
       "         ...,\n",
       "         [ 0.0114, -0.0115, -0.0334,  ...,  0.1298,  0.2577,  0.2563],\n",
       "         [-0.0739,  0.0463,  0.0459,  ..., -0.0542, -0.1925, -0.2289],\n",
       "         [-0.0326, -0.0223, -0.0416,  ...,  0.0332,  0.0778,  0.0940]]),\n",
       " 'SMC': tensor([[-0.0577,  0.0863,  0.0722,  ..., -0.0268, -0.1024, -0.0553],\n",
       "         [-0.0211, -0.0203, -0.0081,  ..., -0.0210, -0.0207,  0.0889],\n",
       "         [-0.0102,  0.0097, -0.0355,  ...,  0.0776,  0.1567,  0.1396],\n",
       "         ...,\n",
       "         [ 0.0291,  0.0089, -0.0097,  ...,  0.1298,  0.2577,  0.2563],\n",
       "         [-0.0875,  0.0553,  0.0482,  ..., -0.0542, -0.1925, -0.2289],\n",
       "         [-0.0481,  0.0017, -0.0111,  ...,  0.0332,  0.0778,  0.0940]]),\n",
       " 'SC': tensor([[-0.0577,  0.0863,  0.0722,  ..., -0.0268, -0.1024, -0.0553],\n",
       "         [-0.0211, -0.0203, -0.0081,  ..., -0.0210, -0.0207,  0.0889],\n",
       "         [-0.0102,  0.0097, -0.0355,  ...,  0.0776,  0.1567,  0.1396],\n",
       "         ...,\n",
       "         [ 0.0291,  0.0089, -0.0097,  ...,  0.1298,  0.2577,  0.2563],\n",
       "         [-0.0875,  0.0553,  0.0482,  ..., -0.0542, -0.1925, -0.2289],\n",
       "         [-0.0481,  0.0017, -0.0111,  ...,  0.0332,  0.0778,  0.0940]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4851b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
